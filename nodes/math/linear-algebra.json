{"all-diagonal-matrices-are-triangular": {"tex": "All diagonal matrices are triangular.", "type": "definition", "proofs": [{"name": "all-diagonal-matrices-are-triangular", "src": ["matrix-diagonal", "matrix-triangular"]}], "width": 390.0, "height": 23.07}, "b-coordinates": {"tex": "Let $\\mathfrak{B}= (\\vec{v}_1,\\vec{v}_2,\\dots,\\vec{v}_d)$ be an ordered basis for a vector space $V,$ and let $v\\in V.$ The $\\mathfrak{B}$-coordinates of $\\vec{v}$ are the unique scalars $a_1,a_2,\\dots,a_n$ such that $\\vec{v}=a_1\\vec{v}_1+a_2\\vec{v}_2+\\dots+a_n\\vec{v}_n.$ We arrange that $\\mathfrak{B}$-coordinates into the column vector $$[v]_{\\mathfrak{B}}=\\begin{bmatrix} a_1\\\\a_2\\\\ \\vdots\\\\a_n \\end{bmatrix},$$ which we call the $\\mathfrak{B}$-coordinate column vector of $\\vec{v}.$", "type": "definition", "defs": [{"id": 1, "src": ["basis"]}], "width": 390.0, "height": 164.25}, "basis": {"tex": "A set $B$ of vectors in a vector space $V$ is called a \\emph{basis} if every element of $V$ may be written as a unique finite linear combination of elements of $B.$", "type": "definition", "defs": [{"id": 1, "src": ["vector-space", "linear-combination"]}], "width": 390.0, "height": 49.73}, "change-of-basis-matrices-are-inverses": {"tex": "Let $V$ be a vector space with bases $\\mathfrak{B}=(b_1,\\dots,b_d)$ and $\\mathfrak{A}=(a_1,\\dots,a_n).$ Then the change of basis matrices $\\cobmatrix{A}{B}$ and $\\cobmatrix{B}{A}$ are inverse to each other.", "proofs": [{"name": "change-of-basis-matrices-are-inverses", "src": ["change-of-basis-theorem-for-coordinates"]}], "type": "corollary", "width": 390.0, "height": 50.4}, "change-of-basis-matrix": {"tex": "Let $V$ be a vector space with bases $\\mathfrak{B}=(b_1,\\dots,b_d)$ and $\\mathfrak{A}=(a_1,\\dots,a_n).$ The \\emph{change of basis matrix} from $\\mathfrak{B}$ to $\\mathfrak{A}$ is the $d\\times d$ matrix $$\\cobmatrix{B}{A} = \\begin{bmatrix} [b_1]_{\\mathfrak{A}} & [b_2]_{\\mathfrak{A}} & \\cdots & [b_n]_{\\mathfrak{A}} \\end{bmatrix}.$$", "type": "definition", "defs": [{"id": 1, "src": ["matrix"]}], "width": 390.0, "height": 69.15}, "change-of-basis-theorem-for-coordinates": {"tex": "Let $V$ be a vector space with bases $\\mathfrak{B}=(b_1,\\dots,b_d)$ and $\\mathfrak{A}=(a_1,\\dots,a_n).$ Then for all $v\\in V,$ $\\cobmatrix{B}{A}[v]_\\mathfrak{B} = [v]_\\mathfrak{A}.$", "proofs": [{"name": "change-of-basis-theorem-for-coordinates", "src": ["change-of-basis-matrix"]}], "type": "theorem", "width": 390.0, "height": 38.9}, "change-of-basis-theorem-for-transformations": {"tex": "Let $V$ be a vector space with bases $\\mathfrak{B}=(b_1,\\dots,b_d)$ and $\\mathfrak{A}=(a_1,\\dots,a_n).$ Let $T:V\\to V$ be a linear transformatoon. Then the matrices of $T$ with respect to $\\mathfrak{A}$ and $\\mathfrak{B}$ are related as follows: $$[T]_\\mathfrak{A} = \\cobmatrix{B}{A}[T]_\\mathfrak{B}\\cobmatrix{A}{B},$$ or equivalently, $$\\cobmatrix{A}{B}[T]_\\mathfrak{A} = [T]_\\mathfrak{B}\\cobmatrix{A}{B}.$$", "proofs": [{"name": "change-of-basis-theorem-for-transformations", "src": ["change-of-basis-matrix"]}], "type": "theorem", "width": 390.0, "height": 120.9}, "coordinate-isomorphism": {"tex": "Let $\\mathfrak{B}= (\\vec{v}_1,\\vec{v}_2,\\dots,\\vec{v}_d)$ be an ordered basis for a vector space $V.$ The map $L_{\\mathfrak{B}}: V \\to \\reals^d$ defined by $\\vec{v}\\mapsto[\\vec{v}]_{\\mathfrak{B}}$ is an isomorphism.", "proofs": [{"name": "coordinate-isomorphism", "src": ["b-coordinates", "isomorphism-of-vector-spaces", "basis"]}], "type": "theorem", "width": 390.0, "height": 38.9}, "determinant-adding-columns": {"tex": "Adding a scalar multiple of one column of a matrix $A$ to another column of $A$ does not change the value of the determinant of $A.$", "type": "corollary", "proofs": [{"name": "determinant-adding-columns", "src": ["determinant-characterization"]}], "width": 390.0, "height": 37.57}, "determinant-characterization": {"tex": "For a square matrix $A$ with columns $a_1,\\dots,a_n,$ the \\emph{determinant} is characterized by: \\begin{enumerate} \\item $\\det(I) = 1$ \\item The determinant is \\emph{alternating:} whenever two columns of $A$ are identical, $\\det A=0.$ \\item The determinant is \\emph{multilinear:} if $\\vec{a}_j=k\\vec{v}+\\vec{w}$ for column vectors $\\vec{v},\\vec{w}$ and scalar $k,$ then $\\det A$ can be expressed as a similar linear combination: $$\\det A = k\\det \\begin{bmatrix}\\vec{a}_1 \\cdots \\vec{v} \\cdots \\vec{a}_n \\end{bmatrix} + \\begin{bmatrix} \\vec{a}_1 \\cdots \\vec{w} \\cdots \\vec{a}_n \\end{bmatrix}.$$\\end{enumerate}", "type": "definition", "defs": [{"id": 1, "src": ["matrix-square", "function"]}], "width": 390.0, "height": 182.98}, "determinant-homogeneous": {"tex": "The determinant is a \\emph{homogeneous function:} $$\\det(k A) = k^n \\det A$$ for an $n\\times n$ matrix $A.$", "proofs": [{"name": "determinant-homogeneous", "src": ["determinant-characterization", "function-homogeneous"]}], "type": "theorem", "width": 390.0, "height": 74.73}, "determinant-interchange-columns": {"tex": "Interchanging any pair of columns of a matrix multiplies its determinant by $-1.$ More generally, any permutation of the columns multiplies the determinant by the sign of the permutation.", "type": "theorem", "proofs": [{"name": "determinant-interchange-columns", "src": ["determinant-characterization"]}], "width": 390.0, "height": 52.07}, "determinant-invertibility": {"tex": "A square matrix $A$ is invertible if and only if $\\det(A)\\neq0.$", "type": "theorem", "proofs": [{"name": "determinant-invertibility", "src": ["determinant-characterization"]}], "width": 390.0, "height": 24.4}, "determinant-invertible-matrix": {"tex": "If $A$ is an invertible matrix, then $\\det A^{-1} = (\\det A)^{-1}.$", "type": "corollary", "proofs": [{"name": "determinant-invertible-matrix-from-multiplicative", "src": ["determinant-multiplicative-property"]}, {"name": "determinant-matrix-inverse-from-elementary-matrices", "src": ["elementary-matrix-inverse-is-elementary", "elementary-matrix-product-determinant", "elementary-matrix-inverse-determinant", "determinant-characterization"]}], "width": 390.0, "height": 24.91}, "determinant-linearly-dependent-columns": {"tex": "If the columns of a matrix $A$ form a linearly dependent set, then $\\det(A)=0.$", "type": "theorem", "proofs": [{"name": "determinant-linearly-dependent-columns", "src": ["determinant-characterization"]}], "width": 390.0, "height": 38.23}, "determinant-multiplicative-property": {"tex": "$\\forall A,B\\in\\reals^{n\\times n},\\ \\det(AB)=\\det A \\det B.$", "type": "theorem", "proofs": [{"name": "determinant-multiplicative-property", "src": ["elementary-matrix-product-determinant", "matrix-inverse-determinant"]}], "width": 390.0, "height": 24.59}, "determinant-orthogonal": {"tex": "The determinant of an orthogonal matrix is $\\pm 1.$", "type": "corollary", "proofs": [{"name": "determinant-orthogonal", "src": ["determinant-transpose"]}], "width": 390.0, "height": 23.07}, "determinant-similar-matrix": {"tex": "Similar matrices have the same determinant.", "type": "corollary", "proofs": [{"name": "determinant-similar-matrix", "src": ["determinant-multiplicative-property"]}], "width": 390.0, "height": 23.07}, "determinant-transpose": {"tex": "If $A$ is an $n\\times n$ matrix, then $\\det A = \\det A^\\top.$", "type": "theorem", "proofs": [{"name": "determinant-transpose", "src": ["determinant-characterization", "matrix-transpose"]}], "width": 390.0, "height": 24.64}, "determinant-triangular": {"tex": "If $A$ is a triangular matrix, then its determinant is the product of its diagonal entires\u2014that is: $$\\det(A) = a_{11}a_{22}\\cdots a_{nn} = \\prod\\limits_{i=1}^{n} a_{ii}.$$", "type": "theorem", "proofs": [{"name": "determinant-triangular", "src": ["determinant-characterization", "matrix-triangular"]}], "width": 390.0, "height": 85.3}, "determinant-zero-column": {"tex": "If a matrix $A$ has a column of zeros, then $\\det(A)=0.$", "type": "corollary", "proofs": [{"name": "determinant-zero-column", "src": ["determinant-linearly-dependent-columns"]}], "width": 390.0, "height": 24.4}, "dimension": {"tex": "The \\emph{dimension} of a vector space $V$ is the cardinality of a basis for $V.$", "type": "definition", "defs": [{"id": 1, "src": ["vector-space", "basis"]}], "width": 390.0, "height": 35.23}, "elementary-matrix": {"tex": "An \\emph{elementary matrix} is an $n\\times n$ matrix obtained by performing a single elementary row operation on an $n\\times n$ matrix. There are three types: \\begin{enumerate} \\item $E_{i\\leftrightarrow j}$ is the matrix obtained from $I_n$ by switching rows $i$ and $j.$ \\item $E_{ii}(\\lambda)$ is the matrix obtained from $I_n$ by scaling row $i$ by some non-zero scalar $\\lambda.$ \\item $E_{ij}(\\lambda)$ is the matrix obtained from $I_n$ by adding a scalar multiple ($\\lambda$) of row $j$ to row $i.$ \\end{enumerate}", "type": "definition", "defs": [{"id": 1, "src": ["matrix-identity"]}], "width": 390.0, "height": 155.23}, "elementary-matrix-determinant-type-1": {"tex": "$\\det(E_{i\\leftrightarrow j}) = -1.$", "type": "fact", "proofs": [{"name": "elementary-matrix-determinant-type-1", "src": ["elementary-matrix", "determinant-characterization"]}], "width": 390.0, "height": 24.76}, "elementary-matrix-determinant-type-2": {"tex": "$\\det(E_{ii}(\\lambda))=\\lambda.$", "type": "fact", "proofs": [{"name": "elementary-matrix-determinant-type-2", "src": ["elementary-matrix", "determinant-characterization"]}], "width": 390.0, "height": 24.4}, "elementary-matrix-determinant-type-3": {"tex": "$\\det(E_{ij}(\\lambda))=1.$", "type": "fact", "proofs": [{"name": "elementary-matrix-determinant-type-3", "src": ["elementary-matrix", "determinant-characterization"]}], "width": 390.0, "height": 24.76}, "elementary-matrix-inverse": {"tex": "Elementary matrices are invertible.", "type": "theorem", "proofs": [{"name": "elementary-matrix-inverse", "src": ["elementary-matrix"]}], "width": 390.0, "height": 23.07}, "elementary-matrix-inverse-determinant": {"tex": "For an elementary matrix $E,$ $\\det(E^{-1})=(\\det E)^{-1}.$", "type": "theorem", "proofs": [{"name": "elementary-matrix-inverse", "src": ["elementary-matrix"]}], "width": 390.0, "height": 24.91}, "elementary-matrix-inverse-is-elementary": {"tex": "The inverse of an elementary matrix is an elementary matrix.", "type": "theorem", "proofs": [{"name": "elementary-matrix-inverse-is-elementary", "src": ["elementary-matrix-inverse", "elementary-matrix"]}], "width": 390.0, "height": 23.07}, "elementary-matrix-invertibility-theorem": {"tex": "Let $A$ be an $n\\times n$ matrix. Then $A$ is invertible if and only if $A$ is the product of a finite number of elementary matrices.", "type": "theorem", "proofs": [{"name": "elementary-matrix-invertibility-theorem", "src": ["elementary-matrix-inverse"]}], "width": 390.0, "height": 37.57}, "elementary-matrix-multiplication-theorem": {"tex": "Let $A$ be an $n\\times m$ matrix. Let $B$ be a matrix obtained from $A$ by an elementary row operation. Then $B=EA$ where $E$ is the $n\\times n$ matrix obtained by performing the same elementary row operation on $I_n.$", "type": "theorem", "proofs": [{"name": "elementary-matrix-multiplication-theorem", "src": ["elementary-matrix"]}], "width": 390.0, "height": 66.03}, "elementary-matrix-product-determinant": {"tex": "Let $A$ be an $n\\times n$ matrix. Then $\\det(EA)=\\det(E)\\det(A).$", "type": "theorem", "proofs": [{"name": "elementary-matrix-product-determinant", "src": ["elementary-matrix-determinant-type-1", "elementary-matrix-determinant-type-2", "elementary-matrix-determinant-type-3", "determinant-characterization"]}], "width": 390.0, "height": 24.4}, "equality-of-sets-definition": {"tex": "Two sets are defined to be equal when they have precisely the same elements.", "type": "definition", "defs": [{"id": 1, "src": ["set"]}], "width": 390.0, "height": 35.23}, "equality-of-sets-from-subsets": {"tex": "Suppose that $X$ and $Y$ are sets. $X=Y$ if and only if $X\\subset Y$ and $Y \\subset X.$", "type": "definition", "defs": [{"id": 1, "src": ["subset", "set"]}], "width": 390.0, "height": 35.7}, "field": {"tex": "A field is a set $F$ with the addition and multiplication operations that satisfies the \\emph{field axioms}: \\begin{enumerate} \\item Closure under addition and multiplication \\item Associativity of addition and multiplication \\item Commutativity of addition and multiplication \\item Additive and multiplicative identity \\item Additive and multiplicative inverse \\item Distributivity of multiplication over addition \\item Distiction of addition and multiplication \\end{enumerate}", "type": "definition", "defs": [{"id": 1, "src": ["ring", "commutativity", "inverse"]}], "width": 390.0, "height": 209.07}, "function": {"tex": "If $X$ and $Y$ are sets, a \\emph{function from $X$ to $Y$} is a subset $f\\subseteq X\\times Y$ with the property that for every element $x\\in X$ there is exactly one element $y\\in Y$ such that $(x,y)\\in f.$", "type": "definition", "defs": [{"id": 1, "src": ["cartesian-product"]}], "width": 390.0, "height": 52.73}, "function-of-several-variables": {"tex": "If $X_1,X_2,\\dots,X_n$ are sets, a \\emph{function of several variables} is a function from $X_1\\times X_2\\times \\dots \\times X_n$ to a set $Y.$", "type": "definition", "defs": [{"id": 1, "src": ["function", "cartesian-product"]}], "width": 390.0, "height": 37.03}, "generalized-key-theorem": {"tex": "Let $T:V\\to V$ be a linear transformation of a vector space $V.$ Let $\\mathfrak{B}=(v_1,\\dots,v_n)$ be an ordered basis for $V.$ Then there exists a unique matrix $B$ such that for all $v\\in V,$ we have $B[v]_\\mathfrak{B}=[T(v)]_\\mathfrak{B}.$ Explicitly, $B=[T]_\\mathfrak{B}.$", "type": "theorem", "proofs": [{"name": "generalized-key-theorem", "src": ["matrix-of-t-wrt-b"]}], "width": 390.0, "height": 67.23}, "image": {"tex": "Given a linear transformation $T:V\\to W$ between vector spaces, the \\emph{image} of $T$ is the subset $\\{T(v):v\\in V\\}.$", "defs": [{"id": 1, "src": ["linear-transformation", "function-forward-image"]}], "type": "definition", "width": 390.0, "height": 38.23}, "inner-product": {"tex": "An \\emph{inner product} on a vector space $V$ is a function $$V\\times V\\to\\reals$$ which assigns each pair of vectors $x,y\\in V$ some scalar $\\langle x,y\\rangle$ called their \\emph{inner product.} The inner product must satisfy the following axioms: \\begin{enumerate} \\item Symmetry: $\\langle x,y\\rangle = \\langle y,x\\rangle$ for all $x\\in V;$ \\item Linearity: $\\langle x+y,z\\rangle = \\langle x,z\\rangle + \\langle x+y,z\\rangle$ and $\\langle kx,y\\rangle = k\\langle x,y\\rangle$ for all $x,y,z\\in V$ and $k\\in\\reals;$ \\item Positive-Definiteness: $\\langle x,x\\rangle > 0$ for all nonzero $x\\in V.$ \\end{enumerate}", "type": "definition", "defs": [{"id": 1, "src": ["vector-space", "function"]}], "width": 390.0, "height": 179.23}, "inner-product-space": {"tex": "A vector space together with a choice of inner product is called an \\emph{inner product space.}", "type": "definition", "defs": [{"id": 1, "src": ["vector-space", "inner-product"]}], "width": 390.0, "height": 37.57}, "isomorphism-of-vector-spaces": {"tex": "An isomorphism of vector spaces is a bijective linear transformation. If there exists an isomorphism $T:V\\to W,$ we say that $V$ and $W$ are isomorphic and we write $V\\cong W.$", "defs": [{"id": 1, "src": ["bijectivity", "linear-transformation"]}], "type": "definition", "width": 390.0, "height": 52.07}, "ker-a-eq-0-implies-ata-invertible": {"tex": "For the $n\\times m$ matrix $A,$ if $\\ker(A)=\\{0\\},$ $A^\\top A$ is invertible.", "type": "corollary", "proofs": [{"name": "ker-a-eq-0-implies-ata-invertible", "src": ["ker-a-eq-ker-ata"]}], "width": 390.0, "height": 25.31}, "ker-a-eq-ker-ata": {"tex": "For the $n\\times m$ matrix $A,$ $$\\ker(A)=\\ker(A^\\top A).$$", "type": "theorem", "proofs": [{"name": "ker-a-eq-ker-ata", "src": ["kernel", "matrix-transpose"]}], "width": 390.0, "height": 50.23}, "kernel": {"tex": "Given a linear transformation $T:V\\to W$ between vector spaces, the \\emph{kernel} of $T$ is the subset $\\{v\\in V:T(v)=0\\}.$", "defs": [{"id": 1, "src": ["linear-transformation"]}], "type": "definition", "width": 390.0, "height": 38.23}, "kernel-image-transpose-complement": {"tex": "If $A$ is $m\\times n$ matrix, then $\\ker A^{\\top}  = (\\im A)^{\\bot}$ and equivalently, $(\\ker A)^{\\bot}  = \\im A^{\\top}.$", "proofs": [{"name": "kernel-image-transpose-complement", "src": ["kernel", "image", "orthogonal-complement"]}], "type": "theorem", "width": 390.0, "height": 39.81}, "key-theorem": {"tex": "Let $T:\\reals^n\\to\\reals^m$ be a linear transformation, and let $A$ be the matrix whose $j$-th column is $T(\\vec{e}_j).$ Then for all $\\vec{x}\\in\\reals^n,$ we have $T(\\vec{x})=A\\vec{x}.$", "type": "theorem", "proofs": [{"name": "key-theorem", "src": ["linear-transformation", "jth-column-of-matrix", "matrix-vector-multiplication", "standard-unit-column-and-row-vectors"]}], "width": 390.0, "height": 52.73}, "least-squares-norm-eq": {"tex": "The least squares solutions of the system $A\\vec{x}=\\vec{b}$ are the exact solutions of the system $$A^\\top A \\vec{x} = A^\\top \\vec{b},$$ which is called the \\emph{normal equation} of $A\\vec{x}=\\vec{b}.$", "type": "theorem", "proofs": [{"name": "least-squares-norm-eq", "src": ["kernel-image-transpose-complement", "kernel"]}], "width": 390.0, "height": 93.95}, "length-of-a-vector": {"tex": "The \\emph{length} (or \\emph{magnitude} or \\emph{norm}) of a vector $\\vec{v}$ in an inner product space is $\\lVert\\vec{v}\\rVert=\\sqrt{\\langle\\vec{v},\\vec{v}\\rangle}.$", "type": "definition", "defs": [{"id": 1, "src": ["inner-product"]}], "width": 390.0, "height": 39.56}, "linear-combination": {"tex": "A \\emph{linear combination} is an expression constructed from a set of terms by multiplying each term by a constant and adding the results.", "type": "definition", "defs": [{"id": 1, "src": ["set", "multiplication", "addition"]}], "width": 390.0, "height": 49.73}, "linear-transformation": {"tex": "Let $V$ and $W$ be vector spaces. A \\emph{linear transformation} from $V$ to $W$ is a map $T:V\\to W$ that satisfies: \\begin{enumerate}\\item $T(x)+T(y)=T(x+y)\\ \\forall x,y\\in V;$ \\item $kT(x)=T(kx)\\ \\forall k\\in\\reals,x\\in V.$ \\end{enumerate}", "defs": [{"id": 1, "src": ["function", "vector-space"]}], "type": "definition", "width": 390.0, "height": 87.23}, "real-matrix": {"tex": "A real \\emph{matrix}, in $\\mathbb{R}^{n\\times m},$ is an $n\\times m$ matrix whose entries are real numbers.", "defs": [{"id": 1, "src": ["real-numbers", "matrix"]}], "type": "definition", "width": 390.0, "height": 36.09}, "matrix-b-transpose-a-inverse": {"tex": "For two matrices $A$ and $B,$ $B^\\top = A^{-1}$ if and only if $B=(A^{-1})^\\top.$", "type": "theorem", "proofs": [{"name": "matrix-b-transpose-a-inverse", "src": ["matrix-transpose"]}], "width": 390.0, "height": 39.81}, "matrix-diagonal": {"tex": "A matrix $A$ is \\emph{diagonal} if $a_{ij}=0$ whenever $i\\neq j.$", "type": "definition", "defs": [{"id": 1, "src": ["matrix"]}], "width": 390.0, "height": 24.09}, "matrix-identity": {"tex": "The identity matrix of size $n$ is the $n\\times n$ square matrix with ones on the main diagonal and 0s elsewhere. Specifically, $(I_n)_{ij} = \\delta_{ij}.$", "type": "definition", "defs": [{"id": 1, "src": ["matrix", "kronecker-delta"]}], "width": 390.0, "height": 38.59}, "matrix-inverse": {"tex": "An $n\\times n$ matrix $A$ is invertible if there exists its inverse, an $n\\times n$ matrix $B$ such that $AB=BA=I_n.$", "type": "definition", "defs": [{"id": 1, "src": ["matrix-identity"]}], "width": 390.0, "height": 37.03}, "matrix-inverse-determinant": {"tex": "Let $A$ be an $n\\times n$ matrix. $A$ is invertible if and only if $\\det(A)\\neq 0.$", "type": "theorem", "proofs": [{"name": "matrix-inverse-determinant", "src": ["elementary-matrix-invertibility-theorem", "determinant-characterization"]}], "width": 390.0, "height": 38.23}, "matrix-lower-triangular": {"tex": "A matrix $A$ is \\emph{lower triangular} if $a_{ij}=0$ whenever $i<j.$", "type": "definition", "defs": [{"id": 1, "src": ["matrix"]}], "width": 390.0, "height": 24.09}, "matrix-of-t-wrt-b": {"tex": "Let $T:V\\to V$ be a linear transformation of a vector space $V.$ Let $\\mathfrak{B}= (\\vec{v}_1,\\vec{v}_2,\\dots,\\vec{v}_n)$ be an ordered basis of $V.$ The matrix of $T$ with respect to $\\mathfrak{B}$ is the $n\\times n$ matrix whose $j$-th column is $[T(v_j)]_{\\mathfrak{B}}$. That is, the matrix of $T$ with respect to $\\mathfrak{B}$ is $$[T]_{\\mathfrak{B}} = \\begin{bmatrix} [T(v_1)]_{\\mathfrak{B}} & [T(v_2)]_{\\mathfrak{B}} & \\cdots & [T(v_n)]_{\\mathfrak{B}} \\end{bmatrix}.$$ For short, we call the $n\\times n$ matrix $[T]_{\\mathfrak{B}}$ the $\\mathfrak{B}$-matrix of $T.$", "defs": [{"id": 1, "src": ["b-coordinates", "linear-transformation"]}], "type": "definition", "width": 390.0, "height": 120.23}, "matrix-skew-symmetric": {"tex": "The matrix $A$ is \\emph{skew-symmetric} if $A=-A^\\top.$", "type": "definition", "defs": [{"id": 1, "src": ["matrix-transpose"]}], "width": 390.0, "height": 24.64}, "matrix-square": {"tex": "An $n\\times m$ is \\emph{square} if $n=m.$", "type": "definition", "defs": [{"id": 1, "src": ["matrix"]}], "width": 390.0, "height": 23.07}, "matrix-symmetric": {"tex": "The matrix $A$ is \\emph{symmetric} if $A=A^\\top.$", "type": "definition", "defs": [{"id": 1, "src": ["matrix-transpose"]}], "width": 390.0, "height": 24.64}, "matrix-transpose": {"tex": "The \\emph{transpose} of the $m\\times n$ matrix $A$ is the $n\\times m$ matrix $A^\\top$ whose $(i,j)$-entry is the $(j,i)$ entry of $A.$", "type": "definition", "defs": [{"id": 1, "src": ["matrix"]}], "width": 390.0, "height": 38.23}, "matrix-triangular": {"tex": "A matrix $A$ is \\emph{triangular} if and only if it is upper triangular or lower triangular.", "type": "definition", "defs": [{"id": 1, "src": ["matrix-upper-triangular", "matrix-lower-triangular"]}], "width": 390.0, "height": 37.57}, "matrix-upper-triangular": {"tex": "A matrix $A$ is \\emph{upper triangular} if $a_{ij}=0$ whenever $i>j.$", "type": "definition", "defs": [{"id": 1, "src": ["matrix"]}], "width": 390.0, "height": 24.09}, "nullity": {"tex": "The \\emph{nullity} of a linear transformation $T:V\\to W$ is the dimension of the kernel of $T.$", "type": "definition", "defs": [{"id": 1, "src": ["linear-transformation", "kernel", "dimension"]}], "width": 390.0, "height": 35.23}, "orthogonal-basis": {"tex": "An \\emph{orthogonal basis} for an inner product space $V$ is a basis for $V$ whose vectors are mutually orthogonal.", "defs": [{"id": 1, "src": ["orthogonality", "basis"]}], "type": "definition", "width": 390.0, "height": 37.57}, "orthogonal-complement": {"tex": "Given any set $S\\subseteq V$ for an inner product space $V,$ the \\emph{orthogonal complement} $S^\\bot$ of $S$ is the set $$S^\\bot = \\{w\\in V:\\langle w,v\\rangle=0\\ \\forall v\\in S \\}.$$", "type": "definition", "defs": [{"id": 1, "src": ["orthogonality"]}], "width": 390.0, "height": 64.73}, "orthogonality": {"tex": "Two vectors $v,w$ in an inner product space $V$ are said to be \\emph{orthogonal} (or \\emph{perpendicular}) if $\\langle v,w\\rangle=0.$", "type": "definition", "defs": [{"id": 1, "src": ["inner-product"]}], "width": 390.0, "height": 38.23}, "orthonormal-basis": {"tex": "An \\emph{orthonormal basis} for an inner product space $V$ is an orthogonal basis for $V$ whose vectors have length 1.", "defs": [{"id": 1, "src": ["orthogonal-basis", "length-of-a-vector"]}], "type": "definition", "width": 390.0, "height": 37.57}, "pythagorean-theorem-inner-product-space": {"tex": "Let $(V,\\ip{\\cdot,\\cdot})$ be an inner product space. Then for all $v,w\\in V,$ $v\\perp w$ iff $\\norm{v+w}^2 = \\norm{v}^2 + \\norm{w}^2.$", "type": "theorem", "proofs": [{"name": "pythagorean-theorem-inner-product-space", "src": ["length-of-a-vector", "orthogonality", "inner-product"]}], "width": 390.0, "height": 38.9}, "rank": {"tex": "The \\emph{rank} of a linear transformation $T:V\\to W$ is the dimension of the image of $T.$", "type": "definition", "defs": [{"id": 1, "src": ["linear-transformation", "image", "dimension"]}], "width": 390.0, "height": 37.57}, "rank-nullity-theorem": {"tex": "Let $T:V\\to W$ be a linear transformation. The \\emph{rank-nullity theorem} states that $\\rank T + \\nullity T = \\dim V.$", "type": "theorem", "proofs": [{"name": "rank-nullity-theorem", "src": ["rank", "nullity", "dimension"]}], "width": 390.0, "height": 37.57}, "standard-matrix": {"tex": "For a linear transformation $T:\\reals^n\\to\\reals^m,$ the \\emph{standard matrix} of $T$ is the matrix such that $T(\\vec{x})=A\\vec{x}$ for all $\\vec{x}\\in\\reals^n.$", "defs": [{"id": 1, "src": ["key-theorem"]}], "type": "definition", "width": 390.0, "height": 38.23}, "linear-subspace": {"tex": "If $V$ is a vector space, a \\emph{linear-subspace} of $V$ is a subset $W$ of $V$ such that \\begin{enumerate} \\item $0_V \\in W;$ \\item $x+y\\in W\\ \\forall x,y\\in W;$ \\item $kx\\in W\\ \\forall k\\in\\reals,x\\in W.$ \\end{enumerate}", "defs": [{"id": 1, "src": ["vector-space"]}], "type": "definition", "width": 390.0, "height": 111.07}, "surjectivity": {"tex": "Let $f:X\\to Y$ be a function. Then $f$ is \\emph{surjective} if and only if $\\forall y\\in Y\\ \\exists x\\in X$ such that $y=f(x).$", "type": "definition", "defs": [{"id": 1, "src": ["function"]}], "width": 390.0, "height": 38.23}, "vector-in-ipspace-as-inner-products": {"tex": "Let $\\mathfrak{B}=(u_1,\\dots,u_n)$ be an orthonormal basis for an inner product space $(V,\\ip{\\cdot,\\cdot}).$ For $x \\in V,$ it holds that $$[x]_\\mathfrak{B} = \\begin{bmatrix} \\ip{x,u_1} \\\\ \\ip{x,u_2} \\\\ \\vdots \\\\ \\ip{x,u_n} \\end{bmatrix}.$$", "type": "theorem", "proofs": [{"name": "vector-in-ipspace-as-inner-products", "src": ["orthonormal-basis", "inner-product-space"]}], "width": 390.0, "height": 116.7}, "vector-in-rn-as-dot-products": {"tex": "Let $\\mathfrak{B}=(\\vec{u}_1,\\dots,\\vec{u}_n)$ be an orthonormal basis for $\\reals^n.$ For $\\vec{x}\\in\\reals^n,$ it holds that $$[\\vec{x}]_\\mathfrak{B} = \\begin{bmatrix} \\vec{x}\\cdot\\vec{u}_1 \\\\ \\vec{x}\\cdot\\vec{u}_2 \\\\ \\vdots \\\\ \\vec{x}\\cdot\\vec{u}_n \\end{bmatrix}.$$", "type": "theorem", "proofs": [{"name": "vector-in-rn-as-dot-products", "src": ["vector-in-ipspace-as-inner-products"]}], "width": 390.0, "height": 104.03}, "vector-space": {"tex": "Given a set $\\mathcal{V}$ and a field $\\mathcal{F}$ with a set of elements $C,$ $(\\mathcal{V},\\mathcal{F})$ is a \\emph{vector space} if for all $u,v,,w\\in V$ and $c,d\\in C$, the \\emph{vector space axioms} hold: \\begin{enumerate} \\item $u+v\\in V$ \\item $u+v = v+u$ \\item $(u+v)+w=u+(v+w)$ \\item $\\exists 0_V \\in V$ s.t. $v+0_V = v$ \\item $\\exists -v\\in V$ s.t. $v+(-v)=0_V.$ \\item $cv\\in V$ \\item $c(u+v)=cu+cv$ \\item $(c+d)v=cv+dv$ \\item $c(dv) = (cd)v$ \\item $1v=v.$ \\end{enumerate}", "type": "definition", "defs": [{"id": 1, "src": ["set", "field"]}], "width": 390.0, "height": 295.4}, "vector": {"tex": "\\emph{Vectors} are elements of a vector space.", "type": "definition", "defs": [{"id": 1, "src": ["vector-space"]}], "width": 390.0, "height": 23.07}, "reduced-row-echelon-form": {"tex": "A matrix is said to be in \\emph{reduced row-echelon form} if it satisfies the following conditions: \\begin{enumerate} \\item if a row has nonzero entries, then the first nonzero entry is a one, called a \\emph{pivot;} \\item if a column contains a pivot, then all other entries in that row are zero; \\item if a row contains a pivot, then each row above it contains a pivot further to the left. \\end{enumerate}The third condition implies that all zero rows are at the bottom of the matrix.", "type": "definition", "defs": [{"id": 1, "src": ["matrix"]}], "width": 390.0, "height": 191.23}, "jth-column-of-matrix": {"tex": "Let $A$ be an $n\\times m$ matrix. The $j$th column of $A$ is the matrix product $$A\\vec{e}_j$$ where $j$ is the $j$th standard unit column vector.", "type": "lemma", "proofs": [{"name": "jth-column-of-matrix", "src": ["matrix-vector-multiplication"]}], "width": 390.0, "height": 73.07}, "standard-unit-column-and-row-vectors": {"tex": "The $j$th standard unit column vector is the column vector $$\\vec{e}_j = \\begin{bmatrix} 0 \\\\ \\vdots \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix}$$ where the $1$ is in the $j$th position.", "type": "theorem", "proofs": [{"name": "standard-unit-column-and-row-vectors", "src": ["reals-n"]}], "width": 390.0, "height": 171.27}, "matrix-vector-multiplication": {"tex": "Let $A$ be an $n\\times m$ matrix and $\\vec{x}$ be an $m\\times 1$ column vector. Then the matrix product $A\\vec{x}$ is an $n\\times 1$ column vector given by $$A\\vec{x} = \\begin{bmatrix} a_{11}x_1 + a_{12}x_2 + \\cdots + a_{1m}x_m \\\\ a_{21}x_1 + a_{22}x_2 + \\cdots + a_{2m}x_m \\\\ \\vdots \\\\ a_{n1}x_1 + a_{n2}x_2 + \\cdots + a_{nm}x_m \\end{bmatrix}.$$", "type": "theorem", "proofs": [{"name": "matrix-vector-multiplication", "src": ["matrix", "column-and-row-vectors"]}], "width": 390.0, "height": 115.59}, "vector-space-reals-n": {"tex": "The coordinate space $\\reals^n$ is a vector space over the field $\\reals$ with the addition of componentwise addition and scalar multiplication. In particular, for $\\vec{x},\\vec{y}\\in\\reals^n$ and $k\\in\reals,$ $$\\vec{x}+\\vec{y} = (x_1+y_1,x_2+y_2,\\ldots,x_n+y_n)$$ and $$k\\vec{x} = (kx_1,kx_2,\\ldots,kx_n).$$ Note that componentwise addition is only defined when the vectors have the same dimension. The zero vector is given by $$\\vec{0} = (0,0,\\ldots,0),$$ and the additive inverse of $\\vec{x}$ is given by $$-\\vec{x} = (-x_1,-x_2,\\ldots,-x_n).$$", "type": "fact", "proofs": [{"name": "vector-space-reals-n", "src": ["reals-n", "vector-space"]}], "width": 390.0, "height": 235.23}, "column-and-row-vectors": {"tex": "In standard matrix notation, each element of $\\reals^n$ is typically written as a column vector like $$\\vec{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n \\end{bmatrix}$$ or sometimes as a column vector like $$\\vec{x} = \\begin{bmatrix} x_1 & x_2 & \\cdots & x_n \\end{bmatrix}.$$", "type": "fact", "defs": [{"id": 1, "src": ["reals-n"]}], "width": 390.0, "height": 165.12}, "reals-n-alternate-definition": {"tex": "The coordinate space $\\reals^n$ is also defined as the set of all column vectors of length $n$ or the set of all row vectors of length $n.$", "type": "fact", "defs": [{"id": 1, "src": ["column-and-row-vectors"]}], "width": 390.0, "height": 37.57}, "matrix": {"tex": "A matrix with entries in a ring $R$ is a triple $(n,m,f)$ where $n,m\\in\\nats$ and $f$ is a map $([n]\\times[m])\\to R$.", "type": "definition", "defs": [{"id": 1, "src": ["natural-numbers", "function", "ring"]}], "author": "Marc van Leuwenn at https://math.stackexchange.com/questions/1811886/what-is-the-most-rigorous-definition-of-a-matrix/1812176#1812176", "width": 390.0, "height": 38.9}, "squared-square-matrix-of-odd-dimension-is-not-negative-multiple-identity-matrix": {"tex": "Let $n$ be an odd natural number and $k$ a negative scalar. Then there does not exist a matrix $M\\in\\reals^{n\\times n}$ such that $M^2 = kI_n.$", "type": "theorem", "proofs": [{"name": "squared-square-matrix-of-odd-dimension-is-not-negative-multiple-identity-matrix", "src": ["natural-exponentiation", "determinant-triangular", "matrix-identity"]}], "source": "Dr. Dobner's Math 217 Qz9 Q2 F22", "width": 390.0, "height": 37.03}, "eigenvector": {"tex": "Let $V$ be a vector space and let $T:V\\to V$ be a linear transformation. A nonzero vector $\\vec{v}\\in V$ is an \\emph{eigenvector} of $T$ if there exists a scalar $\\lambda\\in\\reals$ such that $T(\\vec{v}) = \\lambda\\vec{v}.$", "type": "definition", "defs": [{"id": 1, "src": ["linear-transformation", "vector"]}], "width": 390.0, "height": 52.73}, "eigenvalue": {"tex": "Let $V$ be a vector space and let $T:V\\to V$ be a linear transformation. A scalar $\\lambda\\in\\reals$ is an \\emph{eigenvalue} of $T$ if there exists a nonzero vector $\\vec{v}\\in V$ such that $T(\\vec{v}) = \\lambda\\vec{v}.$", "type": "definition", "defs": [{"id": 1, "src": ["linear-transformation", "vector"]}], "width": 390.0, "height": 52.73}, "lambda-eigenvector": {"tex": "Whenever a pair consisting of a nonzero $\\vec{v}\\in V$ and a scalar $\\lambda\\in\\reals$ satisfies $T(v)=\\lambda v,$ we say that $v$ is an eigenvector of the eigenvalue $\\lambda,$ or that $v$ is a \\emph{$\\lambda$-eigenvector} of $T.$", "type": "definition", "defs": [{"id": 1, "src": ["eigenvector", "eigenvalue"]}], "width": 390.0, "height": 52.29}, "eigenvectors-eigenvalues-of-identity-map": {"tex": "The identity map $I_V$ has eigenvectors $\\vec{v}$ with the eigenvalue $1$ for all nonzero vectors $\\vec{v}\\in V.$", "type": "fact", "proofs": [{"name": "eigenvectors-eigenvalues-of-identity-map", "src": ["eigenvector", "eigenvalue", "identity-map"]}], "width": 390.0, "height": 35.92}, "eigenvectors-eigenvalues-of-zero-map": {"tex": "The zero map $V\\to V$ has eigenvectors $\\vec{v}$ with the eigenvalue $0$ for all nonzero vectors $\\vec{v}\\in V.$", "type": "fact", "proofs": [{"name": "eigenvectors-eigenvalues-of-zero-map", "src": ["eigenvector", "eigenvalue", "zero-map"]}], "width": 390.0, "height": 35.92}, "eigenvectors-eigenvalues-of-scale-map": {"tex": "Let $T:V\\to V$ be the scale map $T(v)=kv$ for positive $k.$ Then $T$ has eigenvectors $\\vec{v}$ with the eigenvalue $k$ for all nonzero vectors $\\vec{v}\\in V.$", "type": "fact", "proofs": [{"name": "eigenvectors-eigenvalues-of-scale-map", "src": ["eigenvector", "eigenvalue", "scale-map"]}], "width": 390.0, "height": 38.23}, "nonzero-vectors-in-kernel-are-eigenvectors": {"tex": "Any nonzero element in the kernel of $T:V\\to V$ is an eigenvector of $T$ with eigenvalue $0.$", "type": "fact", "proofs": [{"name": "nonzero-vectors-in-kernel-are-eigenvectors", "src": ["eigenvector", "eigenvalue", "kernel"]}], "width": 390.0, "height": 37.57}, "transformation-injective-iff-zero-not-eigenvalue": {"tex": "The linear transformation $T:V\\to V$ is injective if and only if zero is not an eigenvalue of $T.$", "type": "fact", "proofs": [{"name": "transformation-injective-iff-zero-not-eigenvalue", "src": ["eigenvector", "eigenvalue", "injectivity"]}], "width": 390.0, "height": 37.57}, "v-eigenvector-implies-kv-eigenvector": {"tex": "If $\\vec{v}$ is an eigenvector of $T,$ then so is $k\\vec{v}$ for any nonzero scalar $k.$", "type": "fact", "proofs": [{"name": "v-eigenvector-implies-kv-eigenvector", "src": ["eigenvector", "eigenvalue"]}], "width": 390.0, "height": 23.29}, "eigenspace": {"tex": "Let $T:V\\to V$ be a linear transformation. Fix any eigenvalue $\\lambda.$ The \\emph{$\\lambda$-eigenspace} of $T$ is the subset of $V$ defined by $$E_\\lambda \\coloneqq \\{v\\in V: T(v) = \\lambda v\\}.$$ That is, it is the set of all eigenvectors of $T$ with eigenvalue $\\lambda$ and the zero vector.", "type": "definition", "defs": [{"id": 1, "src": ["eigenvector", "eigenvalue"]}], "width": 390.0, "height": 102.73}, "eigenspace-is-subspace": {"tex": "Eigenspaces are linear subspaces.", "type": "fact", "proofs": [{"name": "eigenspace-is-subspace", "src": ["eigenspace", "linear-subspace"]}], "width": 390.0, "height": 23.07}, "zero-subspace": {"tex": "The \\emph{zero subspace} is the set $\\{\\vec{0}\\}.$", "type": "definition", "defs": [{"id": 1, "src": ["linear-subspace"]}], "width": 390.0, "height": 26.52}, "lambda-is-eigenvalue-iff-eigenspace-is-nonzero": {"tex": "$\\lambda$ is an eigenvalue of $T$ if and only if $E_\\lambda$ is not the zero subspace.", "type": "fact", "proofs": [{"name": "lambda-is-eigenvalue-iff-eigenspace-is-nonzero", "src": ["eigenspace", "zero-subspace"]}], "width": 390.0, "height": 23.07}, "eigenvalues-orthogonal-transformation": {"tex": "If T is an orthogonal transformation, then the only possible eigenvalues are $1$ or $-1.$", "type": "fact", "proofs": [{"name": "eigenvalues-orthogonal-transformation", "src": ["eigenvalue", "orthogonal-transformations-preserve-length"]}], "width": 390.0, "height": 36.23}, "orthogonal-transformation": {"tex": "An \\emph{orthogonal transformation} is a linear transformation $T:\\reals^n\\to\\reals^n$ on a real inner product space such that $\\ip{u,v} = \\ip{T(u),T(v)}$ for all $u,v\\in\\reals^n.$", "type": "definition", "defs": [{"id": 1, "src": ["linear-transformation", "inner-product-space"]}], "width": 390.0, "height": 52.07}, "orthogonal-transformations-are-injective": {"tex": "Orthogonal transformations are injective.", "type": "fact", "proofs": [{"name": "orthogonal-transformations-are-injective", "src": ["orthogonal-transformation", "injectivity"]}], "width": 390.0, "height": 23.07}, "orthogonal-transformations-preserve-length": {"tex": "Orthogonal transformations preserve length. In particular, $\\norm{T(v)} = \\norm{v}$ for all $v\\in\\reals^n.$", "type": "fact", "proofs": [{"name": "orthogonal-transformations-preserve-length", "src": ["orthogonal-transformation", "length-of-a-vector"]}], "width": 390.0, "height": 38.23}, "orthogonal-transformations-preserve-angles": {"tex": "Orthogonal transformations preserve angles.", "type": "fact", "proofs": [{"name": "orthogonal-transformations-preserve-angles", "src": ["orthogonal-transformation"]}], "width": 390.0, "height": 23.07}, "eigenvalue-of-t-implies-eigenvalue-to-n-of-t-to-n": {"tex": "If $\\lambda$ is an eigenvalue of a linear transformation $T:V\\to V,$ then for $n\\in\\nats,$ $\\lambda^n$ is an eigenvalue of $T^n.$", "type": "fact", "proofs": [{"name": "eigenvalue-of-t-implies-eigenvalue-to-n-of-t-to-n", "src": ["eigenvalue", "linear-transformation"]}], "width": 390.0, "height": 37.57}, "eigenvalue-inverse-transformation": {"tex": "If $T$ is an invertible linear transformation, then all eigenvalues of $T$ are non-zero.", "type": "fact", "proofs": [{"name": "eigenvalue-inverse-transformation", "src": ["eigenvalue", "linear-transformation"]}], "width": 390.0, "height": 35.23}, "eigenbasis": {"tex": "Let $T:V\\to V$ be a linear transformation. A basis $\\mathfrak{B}$ is an \\emph{eigenbasis} for $T$ if every element of the basis is an eigenvector of $T.$", "type": "definition", "defs": [{"id": 1, "src": ["linear-transformation", "basis", "eigenvector"]}], "width": 390.0, "height": 37.57}, "diagonalizable-transformation": {"tex": "Let $T:V\\to V$ be a linear transformation of a finite-dimensional vector space. The map $T$ is \\emph{diagonalizable} if there exists a basis $\\mathfrak{B}$ for $V$ such that $[T]_\\mathfrak{B}$ is diagonal, or equivalently, if there exists an eigenbasis for $T.$", "type": "definition", "defs": [{"id": 1, "src": ["matrix-of-t-wrt-b", "matrix-diagonal", "eigenbasis"]}], "width": 390.0, "height": 66.57}, "diagonalizable-transformation-iff-similar-to-diagonal": {"tex": "The linear map $T$ is diagonalizable if and only if the matrix $[T]_\\mathfrak{B}$ is diagonalizable for some basis $\\mathfrak{B}$ is similar to a diagonal matrix.", "type": "theorem", "proofs": [{"name": "diagonalizable-iff-similar-to-diagonal", "src": ["diagonalizable-transformation", "similar-matrices", "matrix-diagonal"]}], "width": 390.0, "height": 38.23}, "diagonalizable-matrix-iff-similar-to-diagonal": {"tex": "The matrix $A$ is diagonalizable if and only if $A$ is similar to a diagonal matrix.", "type": "theorem", "proofs": [{"name": "diagonalizable-matrix-iff-similar-to-diagonal", "src": ["diagonalizable-matrix", "similar-matrices", "matrix-diagonal"]}], "width": 390.0, "height": 37.57}, "diagonalizable-matrix": {"tex": "An $n\\times n$ matrix $A$ is said to be \\emph{diagonalizable} if the linear transformation $T_A:V\\to V$ defined by $T_A(v) = Av$ is diagonalizable.", "type": "definition", "defs": [{"id": 1, "src": ["diagonalizable-transformation", "standard-matrix"]}], "width": 390.0, "height": 38.23}, "geometric-multiplicity": {"tex": "The \\emph{geometric multiplicity} of an eigenvalue $\\lambda$ of a linear transformation $T:V\\to V$ is the dimension of the $\\lambda$-eigenspace $E_\\lambda.$", "type": "definition", "defs": [{"id": 1, "src": ["eigenvalue", "eigenspace", "dimension"]}], "width": 390.0, "height": 37.57}, "characteristic-polynomial-matrix": {"tex": "The \\emph{characteristic polynomial} of an $n\\times n$ matrix $A$ is $\\chi_A(x) = \\det(A - xI_n).$", "type": "definition", "defs": [{"id": 1, "src": ["matrix", "matrix-identity", "determinant-characterization"]}], "width": 390.0, "height": 38.23}, "characteristic-polynomial-matrix-2x2": {"tex": "Let $A$ be a $2\\times 2$ matrix. Then the characteristic polynomial of $A$ is $\\chi_A(x) = x^2 - \\tr(A)x + \\det(A).$", "type": "fact", "proofs": [{"name": "characteristic-polynomial-matrix-2x2", "src": ["characteristic-polynomial-matrix", "matrix-trace", "determinant-2x2"]}], "width": 390.0, "height": 38.23}, "trace-2x2-in-eigenvalues": {"tex": "Let $A$ be a $2\\times 2$ matrix with eigenvalues $\\lambda_1$ and $\\lambda_2.$ Then $\\tr(A) = \\lambda_1 + \\lambda_2.$", "type": "fact", "proofs": [{"name": "trace-of-2x2-in-eigenvalues", "src": ["matrix-trace", "characteristic-polynomial-matrix-2x2"]}], "width": 390.0, "height": 37.7}, "determinant-2x2-in-eigenvalues": {"tex": "Let $A$ be a $2\\times 2$ matrix with eigenvalues $\\lambda_1$ and $\\lambda_2.$ Then $\\det(A)=\\lambda_1\\lambda_2.$", "type": "fact", "proofs": [{"name": "determinant-2x2-in-eigenvalues", "src": ["determinant-2x2", "characteristic-polynomial-matrix-2x2"]}], "width": 390.0, "height": 37.7}, "determinant-2x2": {"tex": "$$\\det\\begin{pmatrix}a & b\\\\c & d\\end{pmatrix} = ad - bc.$$", "type": "fact", "proofs": [{"name": "determinant-2x2", "src": ["determinant-characterization"]}], "width": 390.0, "height": 50.63}, "matrix-trace": {"tex": "The \\emph{trace} of a matrix $A$ is the sum of the diagonal entries of $A.$", "type": "definition", "defs": [{"id": 1, "src": ["matrix"]}], "width": 390.0, "height": 35.23}, "characteristic-polynomial-transformation": {"tex": "The \\emph{characteristic polynomial} of a linear transformation $T:V\\to V$ is $\\chi_T(x) = \\det([T]_\\mathfrak{B} - xI_n),$ or equivalently, the characteristic polynomial of its standard matrix.", "type": "definition", "defs": [{"id": 1, "src": ["linear-transformation", "matrix-of-t-wrt-b", "matrix-identity", "determinant-characterization"]}, {"id": 2, "src": ["characteristic-polynomial-matrix", "standard-matrix"]}], "width": 390.0, "height": 52.07}, "eigenvalues-are-roots-of-characteristic-polynomial": {"tex": "The eigenvalues of a linear transformation $T:V\\to V$ are the roots of the characteristic polynomial $\\chi_T(x).$", "type": "theorem", "proofs": [{"name": "eigenvalues-are-roots-of-characteristic-polynomial", "src": ["eigenvalue", "characteristic-polynomial-transformation"]}], "width": 390.0, "height": 38.23}, "algebraic-multiplicity": {"tex": "The \\emph{algebraic multiplicity} of an eigenvalue $\\lambda$ of a linear transformation $T:V\\to V$ is the multiplicity of $\\lambda$ as a root of the characteristic polynomial $\\chi_T(x).$", "type": "definition", "defs": [{"id": 1, "src": ["eigenvalue", "characteristic-polynomial-transformation", "multiplicity-of-the-root"]}], "width": 390.0, "height": 52.73}, "eigenvalues-max-number": {"tex": "Let $T:V\\to V$ be a linear transformation of an $n$-dimensional vector space $V.$ There are at most $n$ distinct eigenvalues for $T.$", "type": "theorem", "proofs": [{"name": "eigenvalues-max-number", "src": ["eigenvalue", "dimension"]}], "width": 390.0, "height": 49.73}, "sum-almu-leq-n": {"tex": "Let $T:V\\to V$ be a linear transformation of an $n$-dimensional vector space $V.$ The sum of the algebraic mulitiplicities of the eigenvalues of $T$ is at most $n.$", "type": "theorem", "proofs": [{"name": "sum-almu-leq-n", "src": ["eigenvalue", "dimension", "algebraic-multiplicity"]}], "width": 390.0, "height": 52.07}, "gemu-leq-almu": {"tex": "Let $T:V\\to V$ be a linear transformation of an $n$-dimensional vector space $V.$ The geometric multiplicity of each eigenvalue $\\lambda$ is at most the algebraic multiplicity of $\\lambda.$ We write $\\gemu(\\lambda)\\leq\\almu(\\lambda).$", "type": "theorem", "proofs": [{"name": "gemu-leq-almu", "src": ["eigenvalue", "geometric-multiplicity", "algebraic-multiplicity"]}], "width": 390.0, "height": 52.73}, "eigenvectors-of-distinct-eigenvalues-are-linearly-independent": {"tex": "Eigenvectors of distinct eigenvalues are linearly independent.", "type": "theorem", "proofs": [{"name": "eigenvectors-of-distinct-eigenvalues-are-linearly-independent", "src": ["eigenvalue", "eigenvector"]}], "width": 390.0, "height": 23.07}, "diagonalizable-matrix-only-one-eigenvalue": {"tex": "Suppose $A$ is an $n\\times n$ matrix with only one eigenvalue. If $A$ is diagonalizable, then $A$ is diagonal.", "type": "theorem", "proofs": [{"name": "diagonalizable-matrix-only-one-eigenvalue", "src": ["diagonalizable-matrix", "eigenvalue", "matrix-diagonal"]}], "width": 390.0, "height": 37.57}, "eigenspace-intersection-is-zero-subspace": {"tex": "The intersection of two eigenspaces is a zero subspace.", "type": "theorem", "proofs": [{"name": "eigenspace-intersection-is-zero-subspace", "src": ["eigenspace", "zero-subspace", "set-intersection", "eigenvectors-of-distinct-eigenvalues-are-linearly-independent"]}], "width": 390.0, "height": 23.07}, "similar-matrices": {"tex": "Two $n\\times n$ matrices $A$ and $B$ are \\emph{similar} if there exists an invertible $n\\times n$ matrix $P$ such that $B = PAP^{-1},$ or equivalently, $BP = PA.$", "type": "definition", "defs": [{"id": 1, "src": ["matrix"]}], "width": 390.0, "height": 49.73}, "matrix-multiplication": {"tex": "Let $A$ and $B$ be $m\\times n$ and $n\\times p$ matrices, respectively. Then the product $AB$ is an $m\\times p$ matrix defined by $[AB]_{ij} = \\sum_{k=1}^n [A]_{ik}[B]_{kj}.$", "type": "definition", "defs": [{"id": 1, "src": ["matrix"]}], "width": 390.0, "height": 38.73}, "union-of-bases-for-eigenspaces-is-linearly-independent": {"tex": "Suppose we have $r$ eigenspaces $E_{\\lambda_1},\\ldots,E_{\\lambda_r}$ of a linear transformation $T:V\\to V.$ Let $\\mathfrak{B}_k$ be a basis for the eigenspace $E_{\\lambda_k}.$ Then the union of the bases $\\mathfrak{B}_1,\\ldots,\\mathfrak{B}_r$ is linearly independent.", "type": "theorem", "proofs": [{"name": "union-of-bases-for-eigenspaces", "src": ["eigenspace", "basis", "linear-independence", "set-union"]}], "width": 390.0, "height": 52.07}, "linear-independence": {"tex": "A set of vectors $\\mathfrak{B} = \\{\\mathbf{v}_1,\\ldots,\\mathbf{v}_n\\}$ is \\emph{linearly independent} if no non-zero linear combination of the vectors in $\\mathfrak{B}$ is the zero vector.", "type": "definition", "defs": [{"id": 1, "src": ["vector"]}], "width": 390.0, "height": 35.9}, "linear-combination-of-eigenvectors": {"tex": "Let $T:V\\to V$ be a linear transformation of an $n$-dimensional vector space $V.$ Let $\\mathfrak{B}$ be a basis for the eigenspace $E_{\\lambda}.$ Then any linear combination of the vectors in $\\mathfrak{B}$ is an eigenvector of $T$ with the eigenvalue $\\lambda.$", "type": "theorem", "proofs": [{"name": "linear-combination-of-eigenvectors", "src": ["linear-combination", "linear-transformation", "eigenspace", "basis"]}], "width": 390.0, "height": 66.57}, "eigenbasis-iff-gemu-sum-dimension": {"tex": "Let $T:V\\to V$ be a linear transformation, where $V$ is an $n$-dimensional vector space. $T$ has an eigenbasis if and only if the sum of the geometric multiplicities of its eigenvalues equals $n.$", "type": "theorem", "proofs": [{"name": "eigenbasis-iff-gemu-sum-dimension", "src": ["eigenbasis", "geometric-multiplicity", "dimension", "union-of-bases-for-eigenspaces-is-linearly-independent"]}], "width": 390.0, "height": 52.07}, "eigenbasis-iff-real-eigenvalues-almu-eq-gemu": {"tex": "The transformation $T$ has an eigenbasis if and only if each eigenvalue $\\lambda$ of $T$ is real and satisfies $\\almu(\\lambda) = \\gemu(\\lambda).$", "type": "corollary", "proofs": [{"name": "eigenbasis-iff-real-eigenvalues-almu-eq-gemu", "src": ["eigenbasis-iff-gemu-sum-dimension", "gemu-leq-almu", "sum-almu-leq-n"]}], "width": 390.0, "height": 38.23}}