{
  "addition": {
    "tex": "\\textbf{Definition.} Addition.",
    "type": "axiomatic",
    "width": 32.5,
    "height": 1.73
  },
  "all-diagonal-matrices-are-triangular": {
    "tex": "\\textbf{Theorem.} All diagonal matrices are triangular.",
    "type": "definition",
    "proofs": [
      {
        "name": "all-diagonal-matrices-are-triangular",
        "src": ["matrix-diagonal", "matrix-triangular"]
      }
    ],
    "width": 32.5,
    "height": 1.92
  },
  "b-coordinates": {
    "tex": "\\textbf{Definition.} Let $\\mathfrak{B}= (\\vec{v}_1,\\vec{v}_2,\\dots,\\vec{v}_d)$ be an ordered basis for a vector space $V,$ and let $v\\in V.$ The $\\mathfrak{B}$-coordinates of $\\vec{v}$ are the unique scalars $a_1,a_2,\\dots,a_n$ such that $\\vec{v}=a_1\\vec{v}_1+a_2\\vec{v}_2+\\dots+a_n\\vec{v}_n.$ We arrange that $\\mathfrak{B}$-coordinates into the column vector $$[v]_{\\mathfrak{B}}=\\begin{bmatrix} a_1\\\\a_2\\\\ \\vdots\\\\a_n \\end{bmatrix},$$ which we call the $\\mathfrak{B}$-coordinate column vector of $\\vec{v}.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["basis"] }],
    "width": 32.5,
    "height": 13.69
  },
  "basis": {
    "tex": "\\textbf{Definition.} A set $B$ of vectors in a vector space $V$ is called a \\emph{basis} if every element of $V$ may be written as a unique finite linear combination of elements of $B.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["vector-space", "linear-combination"] }],
    "width": 32.5,
    "height": 4.14
  },
  "bijectivity": {
    "tex": "\\textbf{Definition.} Let $f:X\\to Y$ be a function. Then $f$ is \\emph{bijective} if and only if $f$ is both injective and surjective.",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["injectivity", "surjectivity"] }],
    "width": 32.5,
    "height": 3.13
  },
  "cartesian-product": {
    "tex": "\\textbf{Definition.} For any sets $X$ and $Y,$ the \\emph{Cartesian product} of $X$ and $Y$ is the set $$X\\times Y \\coloneqq \\left\\{(x,y):x\\in X,y\\in Y \\right\\}$$ consisting of all ordered pairs whose first element belongs to $X$ and whose second element belongs to $Y.$ More generally, the \\emph{Cartesian product} of any finite list of sets $(X_1,\\dots,X_n)$ is $$X_1\\times\\cdots\\times X_n \\coloneqq \\{(x_1,\\dots,x_n):x_i\\in X_i\\}.$$ We can use exponential notation for repeated products.",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["set"] }],
    "width": 32.5,
    "height": 12.92
  },
  "change-of-basis-matrices-are-inverses": {
    "tex": "\\textbf{Corollary.} Let $V$ be a vector space with bases $\\mathfrak{B}=(b_1,\\dots,b_d)$ and $\\mathfrak{A}=(a_1,\\dots,a_n).$ Then the change of basis matrices $\\cobmatrix{A}{B}$ and $\\cobmatrix{B}{A}$ are inverse to each other.",
    "proofs": [
      {
        "name": "change-of-basis-matrices-are-inverses",
        "src": ["change-of-basis-theorem-for-coordinates"]
      }
    ],
    "type": "corollary",
    "width": 32.5,
    "height": 4.2
  },
  "change-of-basis-matrix": {
    "tex": "\\textbf{Definition.} Let $V$ be a vector space with bases $\\mathfrak{B}=(b_1,\\dots,b_d)$ and $\\mathfrak{A}=(a_1,\\dots,a_n).$ The \\emph{change of basis matrix} from $\\mathfrak{B}$ to $\\mathfrak{A}$ is the $d\\times d$ matrix $$\\cobmatrix{B}{A} = \\begin{bmatrix} [b_1]_{\\mathfrak{A}} & [b_2]_{\\mathfrak{A}} & \\cdots & [b_n]_{\\mathfrak{A}} \\end{bmatrix}.$$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["matrix"] }],
    "width": 32.5,
    "height": 5.76
  },
  "change-of-basis-theorem-for-coordinates": {
    "tex": "\\textbf{Theorem.} Let $V$ be a vector space with bases $\\mathfrak{B}=(b_1,\\dots,b_d)$ and $\\mathfrak{A}=(a_1,\\dots,a_n).$ Then for all $v\\in V,$ $\\cobmatrix{B}{A}[v]_\\mathfrak{B} = [v]_\\mathfrak{A}.$",
    "proofs": [
      {
        "name": "change-of-basis-theorem-for-coordinates",
        "src": ["change-of-basis-matrix"]
      }
    ],
    "type": "theorem",
    "width": 32.5,
    "height": 3.24
  },
  "change-of-basis-theorem-for-transformations": {
    "tex": "\\textbf{Theorem.} Let $V$ be a vector space with bases $\\mathfrak{B}=(b_1,\\dots,b_d)$ and $\\mathfrak{A}=(a_1,\\dots,a_n).$ Let $T:V\\to V$ be a linear transformatoon. Then the matrices of $T$ with respect to $\\mathfrak{A}$ and $\\mathfrak{B}$ are related as follows: $$[T]_\\mathfrak{A} = \\cobmatrix{B}{A}[T]_\\mathfrak{B}\\cobmatrix{A}{B},$$ or equivalently, $$\\cobmatrix{A}{B}[T]_\\mathfrak{A} = [T]_\\mathfrak{B}\\cobmatrix{A}{B}.$$",
    "proofs": [
      {
        "name": "change-of-basis-theorem-for-transformations",
        "src": ["change-of-basis-matrix"]
      }
    ],
    "type": "theorem",
    "width": 32.5,
    "height": 10.07
  },
  "complex-numbers": {
    "tex": "\\textbf{Definition.} The \\emph{complex numbers} are $\\mathbb{C}$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["real-numbers"] }],
    "width": 32.5,
    "height": 1.92
  },
  "coordinate-isomorphism": {
    "tex": "\\textbf{Theorem.} Let $\\mathfrak{B}= (\\vec{v}_1,\\vec{v}_2,\\dots,\\vec{v}_d)$ be an ordered basis for a vector space $V.$ The map $L_{\\mathfrak{B}}: V \\to \\reals^d$ defined by $\\vec{v}\\mapsto[\\vec{v}]_{\\mathfrak{B}}$ is an isomorphism.",
    "proofs": [
      {
        "name": "coordinate-isomorphism",
        "src": ["b-coordinates", "isomorphism-of-vector-spaces", "basis"]
      }
    ],
    "type": "theorem",
    "width": 32.5,
    "height": 3.24
  },
  "demorgans-laws-sets": {
    "tex": "\\textbf{Theorem.} \\emph{De Morgan's Laws} on sets state that \\begin{enumerate} \\item $(A\\cup B)^\\complement = A^\\complement \\cap B^\\complement,$ \\item $(A\\cap B)^\\complement = A^\\complement \\cup B^\\complement.$ \\end{enumerate}",
    "type": "theorem",
    "proofs": [
      {
        "name": "demorgans-laws-sets",
        "src": [
          "set-union",
          "set-intersection",
          "set-complement",
          "equality-of-sets-from-subsets"
        ]
      }
    ],
    "width": 32.5,
    "height": 6.06
  },
  "determinant-adding-columns": {
    "tex": "\\textbf{Corollary.} Adding a scalar multiple of one column of a matrix $A$ to another column of $A$ does not change the value of the determinant of $A.$",
    "type": "corollary",
    "proofs": [
      {
        "name": "determinant-adding-columns",
        "src": ["determinant-characterization"]
      }
    ],
    "width": 32.5,
    "height": 3.13
  },
  "determinant-characterization": {
    "tex": "\\textbf{Definition.} For a square matrix $A$ with columns $a_1,\\dots,a_n,$ the \\emph{determinant} is characterized by: \\begin{enumerate} \\item $\\det(I) = 1$ \\item The determinant is \\emph{alternating:} whenever two columns of $A$ are identical, $\\det A=0.$ \\item The determinant is \\emph{multilinear:} if $\\vec{a}_j=k\\vec{v}+\\vec{w}$ for column vectors $\\vec{v},\\vec{w}$ and scalar $k,$ then $\\det A$ can be expressed as a similar linear combination: $$\\det A = k\\det \\begin{bmatrix}\\vec{a}_1 \\cdots \\vec{v} \\cdots \\vec{a}_n \\end{bmatrix} + \\begin{bmatrix} \\vec{a}_1 \\cdots \\vec{w} \\cdots \\vec{a}_n \\end{bmatrix}.$$\\end{enumerate}",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["matrix-square", "function"] }],
    "width": 32.5,
    "height": 15.25
  },
  "determinant-homogeneous": {
    "tex": "\\textbf{Theorem.} The determinant is a \\emph{homogeneous function:} $$\\det(k A) = k^n \\det A$$ for an $n\\times n$ matrix $A.$",
    "proofs": [
      {
        "name": "determinant-homogeneous",
        "src": ["determinant-characterization", "function-homogeneous"]
      }
    ],
    "type": "theorem",
    "width": 32.5,
    "height": 6.23
  },
  "determinant-interchange-columns": {
    "tex": "\\textbf{Theorem.} Interchanging any pair of columns of a matrix multiplies its determinant by $-1.$ More generally, any permutation of the columns multiplies the determinant by the sign of the permutation.",
    "type": "theorem",
    "proofs": [
      {
        "name": "determinant-interchange-columns",
        "src": ["determinant-characterization"]
      }
    ],
    "width": 32.5,
    "height": 4.34
  },
  "determinant-invertibility": {
    "tex": "\\textbf{Theorem.} A square matrix $A$ is invertible if and only if $\\det(A)\\neq0.$",
    "type": "theorem",
    "proofs": [
      {
        "name": "determinant-invertibility",
        "src": ["determinant-characterization"]
      }
    ],
    "width": 32.5,
    "height": 2.03
  },
  "determinant-invertible-matrix": {
    "tex": "\\textbf{Corollary.} If $A$ is an invertible matrix, then $\\det A^{-1} = (\\det A)^{-1}.$",
    "type": "corollary",
    "proofs": [
      {
        "name": "determinant-invertible-matrix-from-multiplicative",
        "src": ["determinant-multiplicative-property"]
      },
      {
        "name": "determinant-matrix-inverse-from-elementary-matrices",
        "src": [
          "elementary-matrix-inverse-is-elementary",
          "elementary-matrix-product-determinant",
          "elementary-matrix-inverse-determinant",
          "determinant-characterization"
        ]
      }
    ],
    "width": 32.5,
    "height": 2.08
  },
  "determinant-linearly-dependent-columns": {
    "tex": "\\textbf{Theorem.} If the columns of a matrix $A$ form a linearly dependent set, then $\\det(A)=0.$",
    "type": "theorem",
    "proofs": [
      {
        "name": "determinant-linearly-dependent-columns",
        "src": ["determinant-characterization"]
      }
    ],
    "width": 32.5,
    "height": 3.19
  },
  "determinant-multiplicative-property": {
    "tex": "\\textbf{Theorem.} $\\forall A,B\\in\\reals^{n\\times n},\\ \\det(AB)=\\det A \\det B.$",
    "type": "theorem",
    "proofs": [
      {
        "name": "determinant-multiplicative-property",
        "src": [
          "elementary-matrix-product-determinant",
          "matrix-inverse-determinant",
          "matrix-product-inverse"
        ]
      }
    ],
    "width": 32.5,
    "height": 2.05
  },
  "determinant-orthogonal": {
    "tex": "\\textbf{Corollary.} The determinant of an orthogonal matrix is $\\pm 1.$",
    "type": "corollary",
    "proofs": [
      { "name": "determinant-orthogonal", "src": ["determinant-transpose"] }
    ],
    "width": 32.5,
    "height": 1.92
  },
  "determinant-similar-matrix": {
    "tex": "\\textbf{Corollary.} Similar matrices have the same determinant.",
    "type": "corollary",
    "proofs": [
      {
        "name": "determinant-similar-matrix",
        "src": ["determinant-multiplicative-property"]
      }
    ],
    "width": 32.5,
    "height": 1.92
  },
  "determinant-transpose": {
    "tex": "\\textbf{Theorem.} If $A$ is an $n\\times n$ matrix, then $\\det A = \\det A^\\top.$",
    "type": "theorem",
    "proofs": [
      {
        "name": "determinant-transpose",
        "src": ["determinant-characterization", "matrix-transpose"]
      }
    ],
    "width": 32.5,
    "height": 2.05
  },
  "determinant-triangular": {
    "tex": "\\textbf{Theorem.} If $A$ is a triangular matrix, then its determinant is the product of its columns. That is: $$\\det(A) = a_{11}a_{22}\\cdots a_{nn} = \\prod\\limits_{i=1}^{n} a_{ii}.$$",
    "type": "theorem",
    "proofs": [
      {
        "name": "determinant-triangular",
        "src": ["determinant-characterization", "matrix-triangular"]
      }
    ],
    "width": 32.5,
    "height": 6.91
  },
  "determinant-zero-column": {
    "tex": "\\textbf{Corollary.} If a matrix $A$ has a column of zeros, then $\\det(A)=0.$",
    "type": "corollary",
    "proofs": [
      {
        "name": "determinant-zero-column",
        "src": ["determinant-linearly-dependent-columns"]
      }
    ],
    "width": 32.5,
    "height": 2.03
  },
  "elementary-matrix": {
    "tex": "\\textbf{Definition.} An \\emph{elementary matrix} is an $n\\times n$ matrix obtained by performing a single elementary row operation on an $n\\times n$ matrix. There are three types: \\begin{enumerate} \\item $E_{i\\leftrightarrow j}$ is the matrix obtained from $I_n$ by switching rows $i$ and $j.$ \\item $E_{ii}(\\lambda)$ is the matrix obtained from $I_n$ by scaling row $i$ by some non-zero scalar $\\lambda.$ \\item $E_{ij}(\\lambda)$ is the matrix obtained from $I_n$ by adding a scalar multiple ($\\lambda$) of row $j$ to row $i.$ \\end{enumerate}",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["matrix-identity"] }],
    "width": 32.5,
    "height": 12.94
  },
  "elementary-matrix-determinant": {
    "tex": "\\textbf{Fact.} $\\det(E_{i\\leftrightarrow j}) = -1, \\det(E_{ii}(\\lambda))=\\lambda, \\det(E_{ij}(\\lambda))=1.$",
    "type": "fact",
    "proofs": [
      {
        "name": "elementary-matrix-determinant",
        "src": [
          "elementary-matrix-determinant-type-1",
          "elementary-matrix-determinant-type-2",
          "elementary-matrix-determinant-type-3"
        ]
      }
    ],
    "author": "copilot",
    "width": 32.5,
    "height": 2.06
  },
  "elementary-matrix-determinant-type-1": {
    "tex": "\\textbf{Fact.} $\\det(E_{i\\leftrightarrow j}) = -1.$",
    "type": "fact",
    "proofs": [
      {
        "name": "elementary-matrix-determinant-type-1",
        "src": ["elementary-matrix", "determinant-characterization"]
      }
    ],
    "width": 32.5,
    "height": 2.06
  },
  "elementary-matrix-determinant-type-2": {
    "tex": "\\textbf{Fact.} $\\det(E_{ii}(\\lambda))=\\lambda.$",
    "type": "fact",
    "proofs": [
      {
        "name": "elementary-matrix-determinant-type-2",
        "src": ["elementary-matrix", "determinant-characterization"]
      }
    ],
    "width": 32.5,
    "height": 2.03
  },
  "elementary-matrix-determinant-type-3": {
    "tex": "\\textbf{Fact.} $\\det(E_{ij}(\\lambda))=1.$",
    "type": "fact",
    "proofs": [
      {
        "name": "elementary-matrix-determinant-type-3",
        "src": ["elementary-matrix", "determinant-characterization"]
      }
    ],
    "width": 32.5,
    "height": 2.06
  },
  "elementary-matrix-inverse": {
    "tex": "\\textbf{Theorem.} Elementary matrices are invertible.",
    "type": "theorem",
    "proofs": [
      { "name": "elementary-matrix-inverse", "src": ["elementary-matrix"] }
    ],
    "width": 32.5,
    "height": 1.92
  },
  "elementary-matrix-inverse-determinant": {
    "tex": "\\textbf{Theorem.} For an elementary matrix $E,$ $\\det(E^{-1})=(\\det E)^{-1}.$",
    "type": "theorem",
    "proofs": [
      { "name": "elementary-matrix-inverse", "src": ["elementary-matrix"] }
    ],
    "width": 32.5,
    "height": 2.08
  },
  "elementary-matrix-inverse-is-elementary": {
    "tex": "\\textbf{Theorem.} The inverse of an elementary matrix is an elementary matrix.",
    "type": "theorem",
    "proofs": [
      {
        "name": "elementary-matrix-inverse-is-elementary",
        "src": ["elementary-matrix-inverse", "elementary-matrix"]
      }
    ],
    "width": 32.5,
    "height": 1.92
  },
  "elementary-matrix-invertibility-theorem": {
    "tex": "\\textbf{Theorem.} Let $A$ be an $n\\times n$ matrix. Then $A$ is invertible if and only if $A$ is the product of a finite number of elementary matrices.",
    "type": "theorem",
    "proofs": [
      {
        "name": "elementary-matrix-invertibility-theorem",
        "src": ["elementary-matrix-inverse"]
      }
    ],
    "width": 32.5,
    "height": 3.13
  },
  "elementary-matrix-multiplication-theorem": {
    "tex": "\\textbf{Theorem.} Let $A$ be an $n\\times m$ matrix. Let $B$ be a matrix obtained from $A$ by an elementary row operation. Then $B=EA$ where $E$ is the $n\\times n$ matrix obtained by performing the same elementary row operation on $I_n.$",
    "type": "theorem",
    "proofs": [
      {
        "name": "elementary-matrix-multiplication-theorem",
        "src": ["elementary-matrix"]
      }
    ],
    "width": 32.5,
    "height": 5.5
  },
  "elementary-matrix-product-determinant": {
    "tex": "\\textbf{Theorem.} Let $A$ be an $n\\times n$ matrix. Then $\\det(EA)=\\det(E)\\det(A).$",
    "type": "theorem",
    "proofs": [
      {
        "name": "elementary-matrix-product-determinant",
        "src": ["elementary-matrix-determinant", "determinant-characterization"]
      }
    ],
    "width": 32.5,
    "height": 2.03
  },
  "equality-of-sets-definition": {
    "tex": "\\textbf{Definition.} Two sets are defined to be equal when they have precisely the same elements.",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["set"] }],
    "width": 32.5,
    "height": 2.94
  },
  "equality-of-sets-from-subsets": {
    "tex": "\\textbf{Theorem.} Suppose that $X$ and $Y$ are sets. $X=Y$ if and only if $X\\subset Y$ and $Y \\subset X.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["subset", "set"] }],
    "width": 32.5,
    "height": 2.98
  },
  "field": {
    "tex": "\\textbf{Definition.} A field is a set $F$ with the addition and multiplication operations that satisfies the \\emph{field axioms}: \\begin{enumerate} \\item Closure under addition and multiplication \\item Associativity of addition and multiplication \\item Commutativity of addition and multiplication \\item Additive and multiplicative identity \\item Additive and multiplicative inverse \\item Distributivity of multiplication over addition \\item Distiction of addition and multiplication \\end{enumerate}",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["ring", "commutativity", "inverse"] }],
    "width": 32.5,
    "height": 17.42
  },
  "function": {
    "tex": "\\textbf{Function.} If $X$ and $Y$ are sets, a \\emph{function from $X$ to $Y$} is a subset $f\\subseteq X\\times Y$ with the property that for every element $x\\in X$ there is exactly one element $y\\in Y$ such that $(x,y)\\in f.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["cartesian-product"] }],
    "width": 32.5,
    "height": 4.39
  },
  "function-forward-image": {
    "tex": "\\textbf{Definition.} If $f:X\\to Y$ is any function, then for subsets $A\\subset X$ and $B\\subset Y,$ the \\emph{forward image} (or \\emph{direct image image}) \\emph{of $A$ under $f$} is $$f[A] := \\{f(a)\\in Y:a\\in A\\}.$$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["image", "function"] }],
    "width": 32.5,
    "height": 5.39
  },
  "function-homogeneous": {
    "tex": "\\textbf{Definition.} A \\emph{homogeneous function} is a function of several variables such that, if all its arguments were multiplied by a scalar, then its value is multiplied by some power of this scalar, called the \\emph{degree of homogeneity.} That is, if $k$ is an integer and $f$ is a function of $n$ variables then $f$ is homogeneous of degree $k$ if $$f(sx_1,\\dots,sx_n)=s^kf(x_1,\\dots,x_n)$$ for every $x_1,\\dots,x_n$ and $s\\neq 0.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["function"] }],
    "height": 11.17,
    "width": 32.5
  },
  "function-identity": {
    "tex": "\\textbf{Definition.} For any set $X,$ the \\emph{identity function} $\\text{id}_X : X\\to X$ is defined by the rule $\\text{id}_X(x)=x$ for all $x\\in X.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["function"] }],
    "width": 32.5,
    "height": 3.19
  },
  "function-inverse-image": {
    "tex": "\\textbf{Definition.} If $f:X\\to Y$ is any function, then for subsets $A\\subset X$ and $B\\subset Y,$ the \\emph{preimage} (or \\emph{inverse image}) \\emph{of $B$ under $f$} is $$f^{-1}[B] := \\{x\\in X:f(x)\\in B\\}.$$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["function-value", "function"] }],
    "width": 32.5,
    "height": 5.39
  },
  "function-restriction": {
    "tex": "\\textbf{Definition.} If $f:X\\to Y$ is a function and if $A \\subset X,$ the \\emph{restriction} of $f$ to $A$ is the function $g:A\\to Y$ defined by the rule $g(x)=f(x)$ for all $x\\in A.$ The restriction of $f$ to $A$ is denoted $f\\restriction_A.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["function", "source-and-target"] }],
    "width": 32.5,
    "height": 4.34
  },
  "function-value": {
    "tex": "\\textbf{Definition.} If $f$ is a function from $X$ to $Y$ and $x\\in X,$ the \\emph{value} of $f$ at $x,$ written $f(x),$ is the unique element $y\\in Y$ that $f$ associates to $x.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["image", "function"] }],
    "width": 32.5,
    "height": 3.19
  },
  "generalized-key-theorem": {
    "tex": "\\textbf{Theorem.} Let $T:V\\to V$ be a linear transformation of a vector space $V.$ Let $\\mathfrak{B}=(v_1,\\dots,v_n)$ be an ordered basis for $V.$ Then there exists a unique matrix $B$ such that for all $v\\in V,$ we have $B[v]_\\mathfrak{B}=[T(v)]_\\mathfrak{B}.$ Explicitly, $B=[T]_\\mathfrak{B}.$",
    "type": "theorem",
    "proofs": [
      { "name": "generalized-key-theorem", "src": ["matrix-of-t-wrt-b"] }
    ],
    "width": 32.5,
    "height": 5.6
  },
  "image": {
    "tex": "\\textbf{Definition.} Given a linear transformation $T:V\\to W$ between vector spaces, the \\emph{image} of $T$ is the subset $\\{T(v):v\\in V\\}.$",
    "defs": [{ "id": 1, "src": ["linear-transformation"] }],
    "type": "definition",
    "width": 32.5,
    "height": 3.19
  },
  "injectivity": {
    "tex": "\\textbf{Definition.} Let $f:X\\to Y$ be a function. Then $f$ is \\emph{injective} if and only if $\\forall x,x'\\in X,\\ x\\neq x' \\implies f(x)\\neq f(x').$",
    "defs": [{ "id": 1, "src": ["function"] }],
    "type": "definition",
    "width": 32.5,
    "height": 3.19
  },
  "inner-product": {
    "tex": "\\textbf{Definition.} An \\emph{inner product} on a vector space $V$ is a function $$V\\times V\\to\\reals$$ which assigns each pair of vectors $x,y\\in V$ some scalar $\\langle x,y\\rangle$ called their \\emph{inner product.} The inner product must satisfy the following axioms: \\begin{enumerate} \\item Symmetry: $\\langle x,y\\rangle = \\langle y,x\\rangle;$ \\item Linearity: $\\langle x+y,z\\rangle = \\langle x,z\\rangle + \\langle x+y,z\\rangle$ and $\\langle kx,y\\rangle = k\\langle x,y\\rangle$ for all $x,y,z\\in V$ and $k\\in\\reals;$ \\item Positive-Definiteness: $\\langle x,x\\rangle > 0$ for all nonzero $x\\in V.$ \\end{enumerate}",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["vector-space", "function"] }],
    "width": 32.5,
    "height": 14.94
  },
  "inner-product-space": {
    "tex": "\\textbf{Definition.} A vector space together with a choice of inner product is called an \\emph{inner product space.}",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["vector-space", "inner-product"] }],
    "width": 32.5,
    "height": 3.13
  },
  "integers": {
    "tex": "\\textbf{Definition.} The \\emph{integers} are $\\mathbb{Z}=\\{\\dots,-2,-1,0,1,2,\\dots\\}.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["natural-numbers"] }],
    "width": 32.5,
    "height": 2.03
  },
  "invertibility": {
    "tex": "\\textbf{Theorem.} Let $f:X\\to Y$ be a function. Then $f$ is \\emph{invertible} if and only if $f$ is bijective.",
    "proofs": [
      { "name": "invertibility-from-bijectivity", "src": ["bijectivity"] }
    ],
    "type": "theorem",
    "width": 32.5,
    "height": 3.13
  },
  "isomorphism-of-vector-spaces": {
    "tex": "\\textbf{Definition.} An isomorphism of vector spaces is a bijective linear transformation. If there exists an isomorphism $T:V\\to W,$ we say that $V$ and $W$ are isomorphic and we write $V\\cong W.$",
    "defs": [{ "id": 1, "src": ["bijectivity", "linear-transformation"] }],
    "type": "definition",
    "width": 32.5,
    "height": 4.34
  },
  "ker-a-eq-0-implies-ata-invertible": {
    "tex": "\\textbf{Corollary.} For the $n\\times m$ matrix $A,$ if $\\ker(A)=\\{0\\},$ $A^\\top A$ is invertible.",
    "type": "corollary",
    "proofs": [
      {
        "name": "ker-a-eq-0-implies-ata-invertible",
        "src": ["ker-a-eq-ker-ata"]
      }
    ],
    "width": 32.5,
    "height": 2.11
  },
  "ker-a-eq-ker-ata": {
    "tex": "\\textbf{Theorem.} For the $n\\times m$ matrix $A,$ $$\\ker(A)=\\ker(A^\\top A).$$",
    "type": "theorem",
    "proofs": [
      { "name": "ker-a-eq-ker-ata", "src": ["kernel", "matrix-transpose"] }
    ],
    "width": 32.5,
    "height": 4.19
  },
  "kernel": {
    "tex": "\\textbf{Definition.} Given a linear transformation $T:V\\to W$ between vector spaces, the \\emph{kernel} of $T$ is the subset $\\{v\\in V:T(v)=0\\}.$",
    "defs": [{ "id": 1, "src": ["linear-transformation"] }],
    "type": "definition",
    "width": 32.5,
    "height": 3.19
  },
  "kernel-image-transpose-complement": {
    "tex": "\\textbf{Theorem.} If $A$ is $m\\times n$ matrix, then $\\ker A^{\\top}  = (\\im A)^{\\bot}$ and equivalently, $(\\ker A)^{\\bot}  = \\im A^{\\top}.$",
    "proofs": [
      {
        "name": "kernel-image-transpose-complement",
        "src": ["kernel", "image", "orthogonal-complement"]
      }
    ],
    "type": "theorem",
    "width": 32.5,
    "height": 3.32
  },
  "key-theorem": {
    "tex": "\\textbf{Key Theorem.} Let $T:\\reals^n\\to\\reals^m$ be a linear transformation, and let $A$ be the matrix whose $j$-th column is $T(\\vec{e}_j).$ Then for all $\\vec{x}\\in\\reals^n,$ we have $T(\\vec{x})=A\\vec{x}.$",
    "type": "theorem",
    "width": 32.5,
    "height": 4.39
  },
  "kronecker-delta": {
    "tex": "\\textbf{Definition.} The \\emph{Kronecker delta} is a function of two variables $i,j:$ $$\\delta_{ij} = \\begin{cases} 0 & i\\neq j, \\\\ 1 & i=j.\\end{cases}$$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["function"] }],
    "width": 32.5,
    "height": 6.01
  },
  "least-squares-norm-eq": {
    "tex": "\\textbf{Definition.} The least squares solutions of the system $A\\vec{x}=\\vec{b}$ are the exact solutions of the system $$A^\\top A \\vec{x} = A^\\top \\vec{b},$$ which is called the \\emph{normal equation} of $A\\vec{x}=\\vec{b}.$",
    "type": "theorem",
    "proofs": [
      {
        "name": "least-squares-norm-eq",
        "src": ["kernel-image-transpose-complement", "kernel"]
      }
    ],
    "width": 32.5,
    "height": 7.83
  },
  "length-of-a-vector": {
    "tex": "\\textbf{Definition.} The \\emph{length} (or \\emph{magnitude} or \\emph{norm}) of a vector $\\vec{v}$ in an inner product space is $\\lVert\\vec{v}\\rVert=\\sqrt{\\langle\\vec{v},\\vec{v}\\rangle}.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["inner-product"] }],
    "width": 32.5,
    "height": 3.3
  },
  "linear-combination": {
    "tex": "\\textbf{Definition.} A \\emph{linear combination} is an expression constructed from a set of terms by multiplying each term by a constant and adding the results.",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["set", "multiplication", "addition"] }],
    "width": 32.5,
    "height": 4.14
  },
  "linear-transformation": {
    "tex": "\\textbf{Definition.} Let $V$ and $W$ be vector spaces. A \\emph{linear transformation} from $V$ to $W$ is a map $T:V\\to W$ that satisfies: \\begin{enumerate}\\item $T(x)+T(y)=T(x+y)\\ \\forall x,y\\in V;$ \\item $kT(x)=T(kx)\\ \\forall k\\in\\reals,x\\in V.$ \\end{enumerate}",
    "defs": [{ "id": 1, "src": ["function", "vector-space"] }],
    "type": "definition",
    "width": 32.5,
    "height": 7.27
  },
  "matrix": {
    "tex": "\\textbf{Definition.} \\emph{Matrix} is ... tensor product ... $\\mathbb{R}^{n\\times m}.$",
    "defs": [{ "id": 1, "src": ["vectors-column"] }],
    "type": "definition",
    "width": 32.5,
    "height": 1.99
  },
  "matrix-b-transpose-a-inverse": {
    "tex": "\\textbf{Theorem.} For two matrices $A$ and $B,$ $B^\\top = A^{-1}$ if and only if $B=(A^{-1})^\\top.$",
    "type": "theorem",
    "proofs": [
      { "name": "matrix-b-transpose-a-inverse", "src": ["matrix-transpose"] }
    ],
    "width": 32.5,
    "height": 3.32
  },
  "matrix-diagonal": {
    "tex": "\\textbf{Definition.} The matrix $A$ is \\emph{diagonal} if $a_{ij}=0$ whenever $i\\neq j.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["matrix"] }],
    "width": 32.5,
    "height": 2.01
  },
  "matrix-identity": {
    "tex": "\\textbf{Definition.} The identity matrix of size $n$ is the $n\\times n$ square matrix with ones on the main diagonal and 0s elsewhere. Specifically, $(I_n)_{ij} = \\delta_{ij}.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["matrix", "kronecker-delta"] }],
    "width": 32.5,
    "height": 3.22
  },
  "matrix-inverse": {
    "tex": "\\textbf{Definition.} An $n\\times n$ matrix $A$ is invertible if there exists its inverse, an $n\\times n$ matrix $B$ such that $AB=BA=I_n.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["matrix-identity"] }],
    "width": 32.5,
    "height": 3.09
  },
  "matrix-inverse-determinant": {
    "tex": "\\textbf{Theorem.} Let $A$ be an $n\\times n$ matrix. $A$ is invertible if and only if $\\det(A)\\neq 0.$",
    "type": "theorem",
    "proofs": [
      {
        "name": "matrix-inverse-determinant",
        "src": [
          "elementary-matrix-invertibility-theorem",
          "determinant-characterization"
        ]
      }
    ],
    "width": 32.5,
    "height": 3.19
  },
  "matrix-lower-triangular": {
    "tex": "\\textbf{Definition.} The matrix $A$ is \\emph{lower triangular} if $a_{ij}=0$ whenever $i<j.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["matrix"] }],
    "width": 32.5,
    "height": 2.01
  },
  "matrix-of-t-wrt-b": {
    "tex": "\\textbf{Definition.} Let $T:V\\to V$ be a linear transformation of a vector space $V.$ Let $\\mathfrak{B}= (\\vec{v}_1,\\vec{v}_2,\\dots,\\vec{v}_n)$ be an ordered basis of $V.$ The matrix of $T$ with respect to $\\mathfrak{B}$ is the $n\\times n$ matrix whose $j$-th column is $[T(v_j)]_{\\mathfrak{B}}$. That is, the matrix of $T$ with respect to $\\mathfrak{B}$ is $$[T]_{\\mathfrak{B}} = \\begin{bmatrix} [T(v_1)]_{\\mathfrak{B}} & [T(v_2)]_{\\mathfrak{B}} & \\cdots & [T(v_n)]_{\\mathfrak{B}} \\end{bmatrix}.$$ For short, we call the $n\\times n$ matrix $[T]_{\\mathfrak{B}}$ the $\\mathfrak{B}$-matrix of $T.$",
    "defs": [{ "id": 1, "src": ["b-coordinates", "linear-transformation"] }],
    "type": "definition",
    "width": 32.5,
    "height": 10.02
  },
  "matrix-product-inverse": {
    "tex": "\\textbf{Theorem.} If $A$ or $B$ is not invertible, then neither is $AB.$",
    "type": "theorem",
    "width": 32.5,
    "height": 1.92
  },
  "matrix-skew-symmetric": {
    "tex": "\\textbf{Definition.} The matrix $A$ is \\emph{skew-symmetric} if $A=-A^\\top.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["matrix-transpose"] }],
    "width": 32.5,
    "height": 2.05
  },
  "matrix-square": {
    "tex": "\\textbf{Definition.} The matrix $A\\in\\reals^{n\\times m}$ is \\emph{square} if $n=m.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["matrix"] }],
    "width": 32.5,
    "height": 1.99
  },
  "matrix-symmetric": {
    "tex": "\\textbf{Definition.} The matrix $A$ is \\emph{symmetric} if $A=A^\\top.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["matrix-transpose"] }],
    "width": 32.5,
    "height": 2.05
  },
  "matrix-transpose": {
    "tex": "\\textbf{Definition.} The \\emph{transpose} of the $m\\times n$ matrix $A$ is the $n\\times m$ matrix $A^\\top$ whose $(i,j)$-entry is the $(j,i)$ entry of $A.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["matrix"] }],
    "width": 32.5,
    "height": 3.19
  },
  "matrix-triangular": {
    "tex": "\\textbf{Definition.} The matrix $A$ is \\emph{triangular} if and only if it is upper triangular or lower triangular.",
    "type": "definition",
    "defs": [
      { "id": 1, "src": ["matrix-upper-triangular", "matrix-lower-triangular"] }
    ],
    "width": 32.5,
    "height": 3.13
  },
  "matrix-upper-triangular": {
    "tex": "\\textbf{Definition.} The matrix $A$ is \\emph{upper triangular} if $a_{ij}=0$ whenever $i>j.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["matrix"] }],
    "width": 32.5,
    "height": 2.01
  },
  "multiplication": {
    "tex": "\\textbf{Definition.} Multiplication.",
    "type": "axiomatic",
    "width": 32.5,
    "height": 1.92
  },
  "natural-numbers": {
    "tex": "\\textbf{Definition.} The \\emph{natural numbers} are $\\mathbb{N}=\\{1,2,3,\\dots\\}.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["set"] }],
    "width": 32.5,
    "height": 2.03
  },
  "orthogonal-basis": {
    "tex": "\\textbf{Definition.} An \\emph{orthogonal basis} for an inner product space $V$ is a basis for $V$ whose vectors are mutually orthogonal.",
    "defs": [{ "id": 1, "src": ["orthogonality", "basis"] }],
    "type": "definition",
    "width": 32.5,
    "height": 3.13
  },
  "orthogonal-complement": {
    "tex": "\\textbf{Definition.} Given any set $S\\subseteq V$ for an inner product space $V,$ the \\emph{orthogonal complement} $S^\\bot$ of $S$ is the set $$S^\\bot = \\{w\\in V:\\langle w,v\\rangle=0\\ \\forall v\\in S \\}.$$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["orthogonality"] }],
    "width": 32.5,
    "height": 5.39
  },
  "orthogonality": {
    "tex": "\\textbf{Definition.} Two vectors $v,w$ in an inner product space $V$ are said to be \\emph{orthogonal} (or \\emph{perpendicular}) if $\\langle v,w\\rangle=0.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["inner-product"] }],
    "width": 32.5,
    "height": 3.19
  },
  "orthonormal-basis": {
    "tex": "\\textbf{Definition.} An \\emph{orthonormal basis} for an inner product space $V$ is an orthogonal basis for $V$ whose vectors have length 1.",
    "defs": [{ "id": 1, "src": ["orthogonal-basis", "length-of-a-vector"] }],
    "type": "definition",
    "width": 32.5,
    "height": 3.13
  },
  "power-set": {
    "tex": "\\textbf{Definition.} The \\emph{power set} of a set $S$ is the set of all subsets of $S.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["set", "subset"] }],
    "width": 32.5,
    "height": 1.92
  },
  "pythagorean-theorem-inner-product-space": {
    "tex": "\\textbf{Theorem.} Let $(V,\\ip{\\cdot,\\cdot})$ be an inner product space. Then for all $v,w\\in V,$ $v\\perp w$ iff $\\norm{v+w}^2 = \\norm{v}^2 + \\norm{w}^2.$",
    "type": "theorem",
    "proofs": [
      {
        "name": "pythagorean-theorem-inner-product-space",
        "src": ["length-of-a-vector", "orthogonality", "inner-product"]
      }
    ],
    "width": 32.5,
    "height": 3.24
  },
  "rational-numbers": {
    "tex": "\\textbf{Definition.} The \\emph{rational numbers} is the set of numbers $\\mathbb{Q}$ that can be expressed as a fraction $\\frac{p}{q}$ of two integers, a \\emph{numerator} $q$ and a non-zero \\emph{denominator} $q.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["integers"] }],
    "width": 32.5,
    "height": 4.34
  },
  "real-numbers": {
    "tex": "\\textbf{Definition.} The \\emph{real numbers} are $\\mathbb{R}$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["rational-numbers"] }],
    "width": 32.5,
    "height": 1.73
  },
  "reals-n": {
    "tex": "\\textbf{Definition.} \\emph{Column vectors} are elements of $\\mathbb{R}^n.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["real-numbers", "cartesian-product"] }],
    "width": 32.5,
    "height": 1.73
  },
  "root-2-irrational": {
    "tex": "\\textbf{Theorem.} There is no rational number whose square is $2.$",
    "type": "theorem",
    "proofs": [{ "name": "root-2-irrational", "src": ["rational-numbers"] }],
    "width": 32.5,
    "height": 1.92
  },
  "set": {
    "tex": "\\textbf{Definition.} A \\emph{set} is a collection of different mathematical objects.",
    "type": "axiomatic",
    "width": 32.5,
    "height": 1.92
  },
  "set-complement": {
    "tex": "\\textbf{Definition.} Let $U$ denote a set that contains a subset $A.$ The \\emph{complement of $A$ with respect to $U$} is the set $$A^\\complement = U \\setminus A.$$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["set-difference"] }],
    "width": 32.5,
    "height": 5.39
  },
  "set-difference": {
    "tex": "\\textbf{Definition.} Suppose $A$ and $B$ are sets. The \\emph{difference} of $B$ and $A$ is the set $$B \\setminus A = \\{b \\in B : b\\not\\in A\\}.$$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["set"] }],
    "width": 32.5,
    "height": 4.39
  },
  "set-disjoint": {
    "tex": "\\textbf{Definition.} Two sets are said to be \\emph{disjoint} if their intersection is the empty set.",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["set-intersection", "set-empty"] }],
    "width": 32.5,
    "height": 3.13
  },
  "set-empty": {
    "tex": "\\textbf{Definition.} The \\emph{empty set} (or \\emph{null set}) is the unique set that has no members. It is denoted $\\emptyset.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["set"] }],
    "width": 32.5,
    "height": 3.05
  },
  "set-intersection": {
    "tex": "\\textbf{Definition.} The \\emph{intersection} of sets $A$ and $B$ is the set $$A \\cap B = \\{x : x\\in A\\ \\text{and}\\ x\\in B\\}.$$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["set"] }],
    "width": 32.5,
    "height": 4.19
  },
  "set-union": {
    "tex": "\\textbf{Definition.} The \\emph{union} of sets $A$ and $B$ is the set $$A \\cup B = \\{x : x\\in A\\ \\text{or}\\ x\\in B\\}.$$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["set"] }],
    "width": 32.5,
    "height": 4.19
  },
  "singleton-sets": {
    "tex": "\\textbf{Definition.} A \\emph{singleton set} (or \\emph{unit set}) has exactly one member.",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["set"] }],
    "width": 32.5,
    "height": 2.03
  },
  "source-and-target": {
    "tex": "\\textbf{Definition.} Given a function $f:X\\to Y,$ the set $X$ is called the \\emph{domain} or \\emph{source} of $f,$ and the set $Y$ is called the \\emph{codomain} or \\emph{target} of $f.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["function"] }],
    "width": 32.5,
    "height": 3.13
  },
  "standard-matrix": {
    "tex": "\\textbf{Definition.} For a linear transformation $T:\\reals^n\\to\\reals^m,$ the \\emph{standard matrix} of $T$ is the matrix such that $T(\\vec{x})=A\\vec{x}$ for all $\\vec{x}\\in\\reals^n.$",
    "defs": [{ "id": 1, "src": ["key-theorem"] }],
    "type": "definition",
    "width": 32.5,
    "height": 3.19
  },
  "subset": {
    "tex": "\\textbf{Definition.} If $A$ and $B$ are sets, then $A$ is a \\emph{subset} of $B,$ or $A\\subset B,$ if every element in $A$ is in $B.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["set"] }],
    "width": 32.5,
    "height": 3.13
  },
  "subspace": {
    "tex": "\\textbf{Definition.} If $V$ is a vector space, a \\emph{subspace} of $V$ is a subset $W$ of $V$ such that \\begin{enumerate} \\item $0_V \\in W;$ \\item $x+y\\in W\\ \\forall x,y\\in W;$ \\item $kx\\in W\\ \\forall k\\in\\reals,x\\in W.$ \\end{enumerate}",
    "defs": [{ "id": 1, "src": ["vector-space"] }],
    "type": "definition",
    "width": 32.5,
    "height": 9.26
  },
  "surjectivity": {
    "tex": "\\textbf{Definition.} Let $f:X\\to Y$ be a function. Then $f$ is \\emph{surjective} if and only if $\\forall y\\in Y\\ \\exists x\\in X$ such that $y=f(x).$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["function"] }],
    "width": 32.5,
    "height": 3.19
  },
  "vector-in-ipspace-as-inner-products": {
    "tex": "\\textbf{Theorem.} Let $\\mathfrak{B}=(u_1,\\dots,u_n)$ be an orthonormal basis for an inner product space $(V,\\ip{\\cdot,\\cdot}).$ For $x \\in V,$ it holds that $$[x]_\\mathfrak{B} = \\begin{bmatrix} \\ip{x,u_1} \\\\ \\ip{x,u_2} \\\\ \\vdots \\\\ \\ip{x,u_n} \\end{bmatrix}.$$",
    "type": "theorem",
    "proofs": [
      {
        "name": "vector-in-ipspace-as-inner-products",
        "src": ["orthonormal-basis", "inner-product-space"]
      }
    ],
    "width": 32.5,
    "height": 9.73
  },
  "vector-in-rn-as-dot-products": {
    "tex": "\\textbf{Theorem.} Let $\\mathfrak{B}=(\\vec{u}_1,\\dots,\\vec{u}_n)$ be an orthonormal basis for $\\reals^n.$ For $\\vec{x}\\in\\reals^n,$ it holds that $$[\\vec{x}]_\\mathfrak{B} = \\begin{bmatrix} \\vec{x}\\cdot\\vec{u}_1 \\\\ \\vec{x}\\cdot\\vec{u}_2 \\\\ \\vdots \\\\ \\vec{x}\\cdot\\vec{u}_n \\end{bmatrix}.$$",
    "type": "theorem",
    "proofs": [
      {
        "name": "vector-in-rn-as-dot-products",
        "src": ["vector-in-ipspace-as-inner-products"]
      }
    ],
    "width": 32.5,
    "height": 8.67
  },
  "vector-space": {
    "tex": "\\textbf{Definition.} Given a set $\\mathcal{V}$ and a field $\\mathcal{F}$ with a set of elements $C,$ $(\\mathcal{V},\\mathcal{F})$ is a \\emph{vector space} if for all $u,v,,w\\in V$ and $c,d\\in C$, the \\emph{vector space axioms} hold: \\begin{enumerate} \\item $u+v\\in V$ \\item $u+v = v+u$ \\item $(u+v)+w=u+(v+w)$ \\item $\\exists 0_V \\in V$ s.t. $v+0_V = v$ \\item $\\exists -v\\in V$ s.t. $v+(-v)=0_V.$ \\item $cv\\in V$ \\item $c(u+v)=cu+cv$ \\item $(c+d)v=cv+dv$ \\item $c(dv) = (cd)v$ \\item $1v=v.$ \\end{enumerate}",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["set", "field"] }],
    "width": 32.5,
    "height": 24.62
  },
  "vectors": {
    "tex": "\\textbf{Definition.} \\emph{Vectors} are elements of a vector space.",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["vector-space"] }],
    "width": 32.5,
    "height": 1.92
  },
  "vectors-column": {
    "tex": "\\textbf{Definition.} \\emph{Column vectors} are elements of $\\mathbb{R}^n.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["real-numbers", "cartesian-product"] }],
    "width": 32.5,
    "height": 1.73
  },
  "binary-operation": {
    "tex": "\\textbf{Definition.} Suppose $S$ is a set. A \\emph{binary operation} on $S$ is a function from $S\\times S$ to $S.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["function", "cartesian-product"] }],
    "width": 32.5,
    "height": 3.02
  },
  "associativity": {
    "tex": "\\textbf{Definition.} A binary operation $\\circ$ on a set $S$ is \\emph{associative} if $a\\circ(b\\circ c)=(a\\circ b)\\circ c$ for all $a,b,c\\in S.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["binary-operation"] }],
    "width": 32.5,
    "height": 3.24
  },
  "commutativity": {
    "tex": "\\textbf{Definition.} A binary operation $\\circ$ on a set $S$ is \\emph{commutative} if $a\\circ b=b\\circ a$ for all $a,b\\in S.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["binary-operation"] }],
    "width": 32.5,
    "height": 3.13
  },
  "identity": {
    "tex": "\\textbf{Definition.} A binary operation $\\circ$ on a set $S$ is said to have an \\emph{identity} $e$ if $s\\circ e=e\\circ s=s$ for all $s\\in S.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["binary-operation"] }],
    "width": 32.5,
    "height": 2.98
  },
  "inverse": {
    "tex": "\\textbf{Definition.} Suppose $\\circ$ is a binary operation on a set $S$ and there exists a $\\circ$-identity $e.$ An element $s\\in S$ is said to have an \\emph{inverse} $s^{-1}$ if $s\\circ s^{-1}=s^{-1}\\circ s=e.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["binary-operation", "identity"] }],
    "width": 32.5,
    "height": 4.14
  },
  "z-nz-set": {
    "tex": "\\textbf{Definition.} The \\emph{field of integers modulo $n$} is the set $\\mathbb{Z}/n\\mathbb{Z}$ of integers $z$ such that $0\\leq z < n.$",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["integers", "set"] }],
    "width": 32.5,
    "height": 3.13
  },
  "z-pz-field": {
    "tex": "\\textbf{Theorem.} The \\emph{field of integers modulo $n$} is the a field if and only if $n$ is prime.",
    "type": "Theorem",
    "proofs": [{ "name": "z-pz-field", "src": ["z-nz-set"] }],
    "width": 32.5,
    "height": 3.13
  },
  "ring": {
    "tex": "\\textbf{Definition.} A \\emph{ring} is a set $R$ with the binary operations addition and multiplication that satisfies the \\emph{ring axioms:} \\begin{enumerate} \\item  Associativity of addition and multiplication \\item Commutativity of addition \\item Additive and multiplicative identity \\item Additive inverse \\item Distributivity of multiplication over addition \\end{enumerate}",
    "type": "definition",
    "defs": [
      {
        "id": 1,
        "src": ["set", "associativity", "commutativity", "identity", "inverse"]
      }
    ],
    "width": 32.5,
    "height": 13.34
  },
  "ordered-field": {
    "tex": "\\textbf{Definition.} A field is said to be \\emph{ordered} provided that there is a subset $P\\subset F$ that is closed under addition and multiplication and for which exactly one of following is true for all $f\\in F$ (trichotomy): \\begin{enumerate} \\item $f\\in P$ ($f>0$), \\item $f = 0,$ \\item $-f\\in P$ ($f<0$). \\end{enumerate}",
    "type": "definition",
    "defs": [{ "id": 1, "src": ["field", "subset"] }],
    "width": 32.5,
    "height": 10.52
  },
  "q-ordered": {
    "tex": "\\textbf{Fact.} The set of rational numbers $\\mathbb{Q}$ is ordered.",
    "type": "fact",
    "proofs": [{ "name": "q-ordered", "src": ["q-field", "ordered-field"] }],
    "width": 32.5,
    "height": 1.89
  },
  "r-ordered": {
    "tex": "\\textbf{Fact.} The set of real numbers $\\mathbb{R}$ is ordered.",
    "type": "fact",
    "proofs": [{ "name": "r-ordered", "src": ["r-field", "ordered-field"] }],
    "width": 32.5,
    "height": 1.73
  },
  "c-ordered": {
    "tex": "\\textbf{Fact.} The set of complex numbers $\\mathbb{C}$ is not ordered.",
    "type": "fact",
    "proofs": [{ "name": "c-ordered", "src": ["c-field", "ordered-field"] }],
    "width": 32.5,
    "height": 1.92
  },
  "n-field": {
    "tex": "\\textbf{Fact.} The set of natural numbers $\\mathbb{N}$ is not a field.",
    "type": "theorem",
    "proofs": [{ "name": "n-field", "src": ["natural-numbers", "field"] }],
    "width": 32.5,
    "height": 1.73
  },
  "q-field": {
    "tex": "\\textbf{Fact.} The set of rational numbers $\\mathbb{Q}$ is a field.",
    "type": "fact",
    "proofs": [{ "name": "q-field", "src": ["rational-numbers", "field"] }],
    "width": 32.5,
    "height": 1.89
  },
  "r-field": {
    "tex": "\\textbf{Fact.} The set of real numbers $\\mathbb{R}$ is a field.",
    "type": "fact",
    "proofs": [{ "name": "r-field", "src": ["real-numbers", "field"] }],
    "width": 32.5,
    "height": 1.73
  },
  "c-field": {
    "tex": "\\textbf{Fact.} The set of complex numbers $\\mathbb{C}$ is a field.",
    "type": "fact",
    "proofs": [{ "name": "c-field", "src": ["complex-numbers", "field"] }],
    "width": 32.5,
    "height": 1.92
  }
}
